{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import imageio\n",
    "import pybullet_envs\n",
    "import PIL.Image\n",
    "import pybullet\n",
    "import pybullet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tf_agents.agents.reinforce import reinforce_agent\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "env = gym.make('HumanoidBulletEnv-v0')\n",
    "# env.render(mode='human')\n",
    "env.reset()\n",
    "PIL.Image.fromarray(env.render(mode='rgb_array'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "done = False\n",
    "video_filename = 'humanoid_gym.mp4'\n",
    "with imageio.get_writer(video_filename, fps=60) as video:\n",
    "    while not done:\n",
    "        state, reward, done, info = env.step(env.action_space.sample())\n",
    "        video.append_data(env.render(mode='rgb_array'))\n",
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Pybullet testing environment\n",
    "import PIL.Image\n",
    "import os\n",
    "# Important: pybullet should be charged only once !!\n",
    "from tf_agents.environments import suite_pybullet, parallel_py_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.trajectories.trajectory import Trajectory\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.drivers import dynamic_episode_driver, dynamic_step_driver\n",
    "from tf_agents.policies import random_tf_policy\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florent/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001B[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=320x240 at 0x7FA28421A9D0>",
      "image/png": "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\n"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_env = suite_pybullet.load('HumanoidBulletEnv-v0')\n",
    "py_env.render(mode='human')\n",
    "py_env.reset()\n",
    "PIL.Image.fromarray(py_env.render())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Open Pybullet gui for the humanoid environment\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad state!: 0.7644143104553223\n",
      "bad state!: 0.7669100761413574\n",
      "bad state!: 0.7689265012741089\n",
      "bad state!: 0.7715256214141846\n",
      "bad state!: 0.7759760618209839\n",
      "bad state!: 0.7670365571975708\n",
      "bad state!: 0.763435959815979\n",
      "bad state!: 0.7604746222496033\n",
      "bad state!: 0.756405770778656\n",
      "bad state!: 0.7520368695259094\n",
      "bad state!: 0.7748213410377502\n"
     ]
    },
    {
     "data": {
      "text/plain": "(TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 44), dtype=float32, numpy=\n array([[ 5.99999964e-01,  7.11754046e-06,  1.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00, -0.00000000e+00,  6.08818755e-02,\n          0.00000000e+00,  4.38749433e-01,  0.00000000e+00,\n         -9.28759202e-02,  0.00000000e+00,  1.01374447e+00,\n          0.00000000e+00,  2.75345892e-01,  0.00000000e+00,\n          6.98572040e-01,  0.00000000e+00,  1.06552875e+00,\n          0.00000000e+00,  1.02481306e+00,  0.00000000e+00,\n          2.89953083e-01,  0.00000000e+00,  7.16565192e-01,\n          0.00000000e+00,  1.04809713e+00,  0.00000000e+00,\n          2.39592999e-01,  0.00000000e+00,  2.11571410e-01,\n          0.00000000e+00,  3.61949980e-01,  0.00000000e+00,\n         -1.22260161e-01,  0.00000000e+00, -1.04530536e-01,\n          0.00000000e+00,  3.63283843e-01,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00]], dtype=float32)>),\n ())"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_state_detection = lambda trajectory: print(\"bad state!: {}\".format(trajectory.observation[0][0] + 0.8))\\\n",
    "    if trajectory.observation[0][0] + 0.8 <= 0.78 else None\n",
    "tf_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "stochastic_policy_dir = '/home/florent/Documents/hpc-cluster/saves/stochastic_policy/permissive_variance_policy'\n",
    "policy = tf.compat.v2.saved_model.load(stochastic_policy_dir)\n",
    "dynamic_episode_driver.DynamicEpisodeDriver(tf_env, policy, num_episodes=15, observers=[bad_state_detection]).run()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Perform a few steps in this environment\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001B[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001B[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001B[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001B[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": "TimeStep(step_type=<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 0], dtype=int32)>, reward=<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>, discount=<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>, observation=<tf.Tensor: shape=(4, 44), dtype=float32, numpy=\narray([[ 5.99999964e-01,  1.62427550e-05,  1.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00, -0.00000000e+00,  8.26706067e-02,\n         0.00000000e+00,  5.23690939e-01,  0.00000000e+00,\n        -1.02868237e-01,  0.00000000e+00,  6.21630669e-01,\n         0.00000000e+00,  2.13268593e-01,  0.00000000e+00,\n         7.60154307e-01,  0.00000000e+00,  1.07736683e+00,\n         0.00000000e+00,  8.21396053e-01,  0.00000000e+00,\n         2.49558643e-01,  0.00000000e+00,  7.70442605e-01,\n         0.00000000e+00,  1.01105905e+00,  0.00000000e+00,\n         2.13369042e-01,  0.00000000e+00,  1.76205367e-01,\n         0.00000000e+00,  3.33520561e-01,  0.00000000e+00,\n        -1.54789209e-01,  0.00000000e+00, -1.59752235e-01,\n         0.00000000e+00,  3.66986692e-01,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00],\n       [ 5.99999964e-01,  1.03206194e-05,  1.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00, -0.00000000e+00,  1.24227637e-02,\n         0.00000000e+00,  4.74605501e-01,  0.00000000e+00,\n        -9.12710801e-02,  0.00000000e+00,  7.51267135e-01,\n         0.00000000e+00,  3.25634092e-01,  0.00000000e+00,\n         7.24889278e-01,  0.00000000e+00,  9.93652523e-01,\n         0.00000000e+00,  4.19254601e-01,  0.00000000e+00,\n         2.65222192e-01,  0.00000000e+00,  7.76106417e-01,\n         0.00000000e+00,  9.73551214e-01,  0.00000000e+00,\n         9.52678919e-02,  0.00000000e+00,  1.13712221e-01,\n         0.00000000e+00,  3.04999441e-01,  0.00000000e+00,\n        -2.46093988e-01,  0.00000000e+00, -2.07274452e-01,\n         0.00000000e+00,  2.13064075e-01,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00],\n       [ 5.99999964e-01, -1.48334784e-05,  1.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00, -0.00000000e+00,  6.53072000e-02,\n         0.00000000e+00,  4.93433744e-01,  0.00000000e+00,\n         1.55958489e-01,  0.00000000e+00,  3.48899335e-01,\n         0.00000000e+00,  1.48044035e-01,  0.00000000e+00,\n         6.95008993e-01,  0.00000000e+00,  9.78836238e-01,\n         0.00000000e+00,  4.66428697e-01,  0.00000000e+00,\n         2.88384587e-01,  0.00000000e+00,  7.70202696e-01,\n         0.00000000e+00,  1.05969596e+00,  0.00000000e+00,\n         1.35152355e-01,  0.00000000e+00,  1.11097723e-01,\n         0.00000000e+00,  2.80258656e-01,  0.00000000e+00,\n        -1.04267113e-01,  0.00000000e+00, -2.46149927e-01,\n         0.00000000e+00,  3.48339379e-01,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00],\n       [ 5.99999964e-01,  2.02693263e-05,  1.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00, -0.00000000e+00, -7.65241161e-02,\n         0.00000000e+00,  5.00495613e-01,  0.00000000e+00,\n        -1.60097346e-01,  0.00000000e+00,  3.14469486e-01,\n         0.00000000e+00,  3.33875239e-01,  0.00000000e+00,\n         6.92609966e-01,  0.00000000e+00,  9.89695549e-01,\n         0.00000000e+00,  4.85491276e-01,  0.00000000e+00,\n         3.77303928e-01,  0.00000000e+00,  6.71423078e-01,\n         0.00000000e+00,  9.61403668e-01,  0.00000000e+00,\n         1.13194615e-01,  0.00000000e+00,  2.02470317e-01,\n         0.00000000e+00,  3.21283132e-01,  0.00000000e+00,\n        -1.09317124e-01,  0.00000000e+00, -1.16468772e-01,\n         0.00000000e+00,  2.97178626e-01,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00]], dtype=float32)>)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parallel environments.\n",
    "num_parallel_environments = 4\n",
    "tf_env = tf_py_environment.TFPyEnvironment(parallel_py_environment.ParallelPyEnvironment(\n",
    "    [lambda : suite_pybullet.load('HumanoidBulletEnv-v0')] * num_parallel_environments))\n",
    "tf_env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load a tf parallel environment (4 parallel environments)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.8/site-packages/tf_agents/drivers/dynamic_step_driver.py:194: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.8/site-packages/tf_agents/drivers/dynamic_step_driver.py:194: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
     ]
    },
    {
     "data": {
      "text/plain": "(TimeStep(step_type=<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 1, 1, 1], dtype=int32)>, reward=<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-1.2963152 , -1.6380416 , -0.52739006, -1.92463   ], dtype=float32)>, discount=<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>, observation=<tf.Tensor: shape=(4, 44), dtype=float32, numpy=\n array([[ 1.41910478e-01,  2.24777535e-01,  9.74410117e-01,\n          2.37449810e-01,  2.63552248e-01, -6.33577824e-01,\n         -1.33746654e-01,  7.17802167e-01,  6.99439764e-01,\n         -1.12185681e+00, -7.12890208e-01,  2.94008046e-01,\n         -5.12470484e-01,  3.76603752e-01, -1.01171613e+00,\n          1.85896084e-02,  9.36529696e-01,  7.74048746e-01,\n          3.32406670e-01, -1.66280806e+00, -9.90635574e-01,\n          1.30568832e-01, -2.87722021e-01,  1.92546487e+00,\n         -9.95755382e-03, -1.73471045e+00, -3.14798415e-01,\n         -1.84185243e+00, -9.54341292e-01,  6.57576680e-01,\n          1.75604165e-01, -8.73610079e-02,  1.65598571e-01,\n         -8.09200823e-01, -2.44794235e-01,  1.14571476e+00,\n          2.17054501e-01, -1.04799896e-01, -1.61474019e-01,\n          2.40449421e-02,  1.04367554e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00],\n        [ 4.04553264e-01,  1.44645989e-01,  9.89483476e-01,\n         -4.15961370e-02,  1.57159416e-03, -8.51657867e-01,\n         -7.78672635e-04,  2.16240324e-02,  6.30098939e-01,\n          1.67430758e-01,  6.64104402e-01,  1.02945462e-01,\n          7.28429481e-02,  4.54298764e-01,  9.85747278e-01,\n         -1.42044258e+00, -9.43021417e-01, -6.42900541e-02,\n         -3.32495958e-01, -6.40406087e-02, -3.08869302e-01,\n         -1.35241342e+00,  9.59878564e-01, -1.63304005e-02,\n          4.02427524e-01,  7.04422355e-01, -3.44529927e-01,\n         -1.18397546e+00, -3.09049219e-01, -1.50936639e+00,\n          1.34892473e-02, -1.41894996e-01,  2.92788208e-01,\n          1.25683010e-01, -5.44942856e-01, -2.10525155e+00,\n         -5.37955500e-02,  1.50009722e-01, -5.06133176e-02,\n         -4.63220716e-01, -1.06544292e+00, -3.61096406e+00,\n          0.00000000e+00,  0.00000000e+00],\n        [-6.55305630e-04, -6.70097411e-01,  7.42273211e-01,\n          2.17396021e-01, -7.61320964e-02, -9.92672384e-01,\n          8.62337053e-01,  7.72424757e-01, -8.54066789e-01,\n         -4.69194651e-01, -8.26390743e-01, -4.63894725e-01,\n         -2.23326862e-01,  4.07838106e-01, -7.37365007e-01,\n          7.66245544e-01, -6.85036957e-01, -9.23553035e-02,\n         -5.63982844e-01, -8.91454816e-01, -5.57616234e-01,\n          7.78154135e-01, -7.00998425e-01,  9.56430018e-01,\n         -5.93841016e-01, -1.79694104e+00,  1.10730395e-01,\n         -7.26297677e-01, -8.29543054e-01, -5.55596113e-01,\n         -3.72005194e-01, -3.44548970e-01,  3.03794717e-04,\n          9.25054401e-02,  1.08242059e+00,  0.00000000e+00,\n         -5.06434083e-01, -3.67241234e-01, -7.00879335e-01,\n          3.75387192e-01, -2.66399328e-02,  1.48349178e+00,\n          0.00000000e+00,  0.00000000e+00],\n        [ 2.65823066e-01, -9.92657781e-01,  1.20956503e-01,\n         -2.38880157e-01,  1.61445305e-01, -7.09449291e-01,\n          1.15549242e+00,  9.91330504e-01, -3.52418989e-01,\n         -1.44712389e+00, -3.74580324e-01, -2.06932497e+00,\n         -8.20255652e-02, -3.90021741e-01, -1.03025067e+00,\n          4.85725015e-01, -1.08681358e-01,  7.14008391e-01,\n         -2.93873072e-01,  6.81674108e-02,  6.74180448e-01,\n         -6.41691446e-01,  9.58481908e-01, -1.58573702e-01,\n          3.08498621e-01, -1.12321770e+00, -1.00111532e+00,\n          8.25853925e-03, -2.64967203e-01, -1.41426492e+00,\n         -2.85053730e-01, -3.51779222e-01, -8.42941701e-01,\n         -1.80430865e+00, -1.01034153e+00,  7.65724257e-02,\n         -6.49000555e-02,  4.71559390e-02, -4.56650317e-01,\n         -7.06086814e-01,  1.01409841e+00, -1.04391009e-01,\n          0.00000000e+00,  0.00000000e+00]], dtype=float32)>),\n ())"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer_size = 12800\n",
    "\n",
    "# create a dataset\n",
    "from tf_agents.agents.reinforce import reinforce_agent\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "    tf_env.observation_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    fc_layer_params=(128, 128))\n",
    "policy = random_tf_policy.RandomTFPolicy(tf_env.time_step_spec(), tf_env.action_spec())\n",
    "train_step_counter = tf.compat.v2.Variable(0)\n",
    "\n",
    "agent = reinforce_agent.ReinforceAgent(\n",
    "    tf_env.time_step_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    actor_network=actor_net,\n",
    "    optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4),\n",
    "    normalize_returns=True,\n",
    "    train_step_counter=train_step_counter)\n",
    "agent.initialize()\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=tf_env.batch_size,\n",
    "    max_length=replay_buffer_size)\n",
    "whole_dataset = replay_buffer.as_dataset(num_parallel_calls=3, sample_batch_size=replay_buffer_size, num_steps=3)\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(tf_env.time_step_spec(), tf_env.action_spec())\n",
    "dynamic_step_driver.DynamicStepDriver(tf_env, random_policy,\n",
    "                                      observers=[replay_buffer.add_batch], num_steps=replay_buffer_size).run()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Fill in a replay buffer\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def labeling_function(states):\n",
    "    return states[..., 0] + 0.8 <= 0.78"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% define a labeling function\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering tf.Tensor(False, shape=(), dtype=bool)\n",
      "state_type tf.Tensor([1 1], shape=(2,), dtype=int32)\n",
      "next_state_type tf.Tensor([1 1], shape=(2,), dtype=int32)\n",
      "states tf.Tensor(\n",
      "[[ 1.8663943e-01  8.4217668e-01  5.3920168e-01 -6.3637875e-02\n",
      "   7.7022254e-03 -7.6459742e-01 -1.0190836e+00  8.1865209e-01\n",
      "   6.7273396e-01 -1.6643259e-01 -1.0509474e+00  3.9145800e-01\n",
      "   9.1406935e-01  1.2099795e+00 -1.0131489e+00  2.4945411e-01\n",
      "   1.6147812e-01 -5.0068551e-01 -2.5706881e-01 -1.2739486e-01\n",
      "  -7.1134549e-01 -4.8811191e-01 -1.0299126e+00  4.7461286e-02\n",
      "   2.2694165e-01 -1.3708428e-01 -5.1301479e-01  4.5426375e-01\n",
      "  -9.1057992e-01  5.7339650e-02 -1.8074872e-01 -3.2498407e-01\n",
      "   6.5933275e-01  6.7339754e-01  6.7635870e-01 -2.0521264e+00\n",
      "   5.7353610e-01  2.4923790e-01  2.6293305e-01  6.4210427e-01\n",
      "   1.0513445e+00 -1.5953971e-10  0.0000000e+00  0.0000000e+00]\n",
      " [ 1.4566535e-01  8.5097790e-01  5.2520150e-01  7.6522060e-02\n",
      "  -6.3309789e-02 -7.2146624e-01 -9.9750495e-01  7.3026425e-01\n",
      "   7.7555203e-01  9.8332322e-01 -1.0052681e+00  1.5780246e-01\n",
      "   1.0182134e+00 -2.4224499e-01 -7.3997164e-01  5.5731219e-01\n",
      "   2.9610667e-02 -8.0933678e-01 -2.6295286e-01 -4.1742711e-03\n",
      "  -7.4289048e-01 -1.3346264e-01 -1.0122522e+00  1.9440142e-02\n",
      "   2.2131175e-01  4.7068197e-02 -4.6127662e-01  2.7003965e-01\n",
      "  -9.0102047e-01  6.8284050e-02 -2.2956294e-01 -4.0744174e-01\n",
      "   7.5979823e-01  8.2579237e-01  3.4980118e-01 -2.6349185e+00\n",
      "   6.2047023e-01  4.2926863e-01  3.5413161e-01  7.2965932e-01\n",
      "   1.0513428e+00 -1.6065652e-10  0.0000000e+00  0.0000000e+00]], shape=(2, 44), dtype=float32)\n",
      "next_states tf.Tensor(\n",
      "[[ 1.4566535e-01  8.5097790e-01  5.2520150e-01  7.6522060e-02\n",
      "  -6.3309789e-02 -7.2146624e-01 -9.9750495e-01  7.3026425e-01\n",
      "   7.7555203e-01  9.8332322e-01 -1.0052681e+00  1.5780246e-01\n",
      "   1.0182134e+00 -2.4224499e-01 -7.3997164e-01  5.5731219e-01\n",
      "   2.9610667e-02 -8.0933678e-01 -2.6295286e-01 -4.1742711e-03\n",
      "  -7.4289048e-01 -1.3346264e-01 -1.0122522e+00  1.9440142e-02\n",
      "   2.2131175e-01  4.7068197e-02 -4.6127662e-01  2.7003965e-01\n",
      "  -9.0102047e-01  6.8284050e-02 -2.2956294e-01 -4.0744174e-01\n",
      "   7.5979823e-01  8.2579237e-01  3.4980118e-01 -2.6349185e+00\n",
      "   6.2047023e-01  4.2926863e-01  3.5413161e-01  7.2965932e-01\n",
      "   1.0513428e+00 -1.6065652e-10  0.0000000e+00  0.0000000e+00]\n",
      " [ 1.0771312e-01  8.6870277e-01  4.9533373e-01  5.8246750e-02\n",
      "  -1.4445956e-01 -6.6293722e-01 -9.7481173e-01  6.5309650e-01\n",
      "   9.3341976e-01  6.6136914e-01 -1.0021578e+00  1.1982961e-02\n",
      "   1.0055054e+00 -2.0374319e-02 -4.4136140e-01  4.1672170e-01\n",
      "  -1.3735840e-01 -8.7683284e-01 -2.0356140e-01  6.7504472e-01\n",
      "  -7.3358649e-01  2.0449376e-01 -8.8469011e-01  2.6845485e-01\n",
      "   2.6487029e-01  2.8198975e-01 -3.5525510e-01  1.0509812e+00\n",
      "  -8.7091768e-01  3.4969899e-01 -2.9476628e-01 -5.5052096e-01\n",
      "   8.7219465e-01  8.8937205e-01  1.0687295e-01 -1.3137113e+00\n",
      "   6.7809153e-01  4.1804388e-01  4.4525945e-01  6.7653662e-01\n",
      "   1.0513427e+00 -1.0704920e-06  0.0000000e+00  0.0000000e+00]], shape=(2, 44), dtype=float32)\n",
      "rewards tf.Tensor(\n",
      "[[-0.00861945]\n",
      " [-1.2436602 ]], shape=(2, 1), dtype=float32)\n",
      "next_labels tf.Tensor(\n",
      "[[False]\n",
      " [False]], shape=(2, 1), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "import tf_agents.trajectories.time_step as ts\n",
    "\n",
    "scalar_rewards = True\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    num_steps=3).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "iterator = iter(dataset)\n",
    "raw_data, _ = next(iterator)\n",
    "\n",
    "\n",
    "state_type = raw_data.step_type[:2]\n",
    "next_state_type = raw_data.next_step_type[:2]\n",
    "\n",
    "# remove transitions where the incident state is terminal and next state is initial\n",
    "# note: such transitions correspond to those where the reset() function has been called\n",
    "filtering = state_type[0] != ts.StepType.LAST\n",
    "filtering &= state_type[1] != ts.StepType.LAST\n",
    "filtering &= next_state_type[0] != ts.StepType.FIRST\n",
    "filtering &= next_state_type[1] != ts.StepType.FIRST\n",
    "filtering = tf.reduce_all(filtering)\n",
    "\n",
    "print(\"filtering\", filtering)\n",
    "print(\"state_type\", state_type)\n",
    "print(\"next_state_type\", next_state_type)\n",
    "\n",
    "states = raw_data.observation[:2, :]\n",
    "actions = raw_data.action[:2, :]\n",
    "rewards = raw_data.reward[:2] if scalar_rewards else reward[:2, :]\n",
    "if scalar_rewards:\n",
    "    rewards = tf.reshape(rewards, list(rewards.shape) + [1])\n",
    "next_states = raw_data.observation[1:, :]\n",
    "next_labels = labeling_function(next_states)\n",
    "if next_labels.shape == states.shape[:-1]:\n",
    "    next_labels = tf.reshape(next_labels, list(next_labels.shape) + [1])\n",
    "\n",
    "print(\"states\", states)\n",
    "print(\"next_states\", next_states)\n",
    "print(\"rewards\", rewards)\n",
    "print(\"next_labels\", next_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tf_agents.trajectories.time_step as ts\n",
    "import datetime\n",
    "\n",
    "dataset_path = 'dataset'\n",
    "iterator = iter(dataset)\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "with h5py.File(dataset_path + '/rl_exploration' + current_time + '.hdf5', 'w') as h5f:\n",
    "    data = iterator.next()[0]\n",
    "    states = data.observation[:, :2, :].numpy()\n",
    "    actions = data.action[:, :2, :].numpy()\n",
    "    rewards = data.reward[:, :2].numpy()\n",
    "    next_states = data.observation[:, 1:, :].numpy()\n",
    "    next_labels = labeling_function(next_states)\n",
    "    # 0: initial state; 1: mid state; 2: terminal state\n",
    "    state_type = data.step_type[:, :2].numpy()\n",
    "    next_state_type = data.next_step_type[:, :2].numpy()\n",
    "\n",
    "    # remove transitions where the incident state is terminal and next state is initial\n",
    "    filtering = state_type[:, 0] != ts.StepType.LAST\n",
    "    filtering &= state_type[:, 1] != ts.StepType.LAST\n",
    "    filtering &= next_state_type[:, 0] != ts.StepType.FIRST\n",
    "    filtering &= next_state_type[:, 1] != ts.StepType.FIRST\n",
    "\n",
    "    h5f['state'] = states[filtering]\n",
    "    h5f['action'] = actions[filtering]\n",
    "    h5f['reward'] = rewards[filtering]\n",
    "    h5f['next_state'] = next_states[filtering]\n",
    "    h5f['next_state_label'] = next_labels[filtering]\n",
    "    # 0: initial state; 1: mid state; 2: terminal state\n",
    "    h5f['state_type'] = state_type[filtering]\n",
    "    h5f['next_state_type'] = state_type[filtering]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% h5py: store a dataset from the replay memory\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import glob\n",
    "import os\n",
    "\n",
    "file_list: List[str] = glob.glob(os.path.join(dataset_path, 'rl_*')) + \\\n",
    "                       glob.glob(os.path.join(dataset_path, 'reinforcement_learning', 'rl_*'))\n",
    "print(\"File list:\")\n",
    "print(file_list)\n",
    "\n",
    "length: int = 0\n",
    "h5f_indices: Dict[str, Tuple[int, int]] = {}\n",
    "shape: Dict[str, Tuple[int, ...]] = {}\n",
    "dataset_name = 'rl_observation_dataset.hdf5'\n",
    "\n",
    "for h5f_name in file_list:\n",
    "    with h5py.File(h5f_name, 'r') as h5f:\n",
    "        h5f_length = h5f['state'].shape[0]  # we assume that all h5f datasets have the same length (= size of axis 0)\n",
    "        h5f_indices[h5f_name] = (length, length + h5f_length)\n",
    "        length += h5f_length\n",
    "\n",
    "for i, h5f_name in enumerate(file_list):\n",
    "    with h5py.File(h5f_name, 'r') as h5f:\n",
    "        with h5py.File(os.path.join(dataset_path, dataset), 'w') as merged_h5f:\n",
    "            for key in h5f:\n",
    "                if i == 0:  # dataset file initialization\n",
    "                    shape[key] = (length, ) + h5f[key].shape[1:]\n",
    "                    merged_h5f.create_dataset(key, shape[key], dtype=h5f[key].dtype)\n",
    "                first, last = h5f_indices[h5f_name]\n",
    "                merged_h5f[key][first: last] = h5f[key]\n",
    "\n",
    "print(\"Dataset files merged\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% h5py: merge two stored datasets\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class generator:\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "\n",
    "    def __call__(self):\n",
    "        with h5py.File(self.file, 'r') as hf:\n",
    "            for (state, action, reward, next_state, label, state_type, next_state_type) in \\\n",
    "                zip(hf['state'], hf['action'], hf['reward'], hf['next_state'],\n",
    "                    hf['next_state_label'], hf['state_type'], hf['next_state_type']):\n",
    "                yield state, action, reward, next_state, label, state_type, next_state_type\n",
    "\n",
    "    def get_tensor_shape(self):\n",
    "        with h5py.File(self.file, 'r') as hf:\n",
    "           return (tf.TensorShape(hf['state'].shape[1:]),\n",
    "                   tf.TensorShape(hf['action'].shape[1:]),\n",
    "                   tf.TensorShape(hf['reward'].shape[1:]),\n",
    "                   tf.TensorShape(hf['next_state'].shape[1:]),\n",
    "                   tf.TensorShape(hf['next_state_label'].shape[1:]),\n",
    "                   tf.TensorShape(hf['state_type'].shape[1:]),\n",
    "                   tf.TensorShape(hf['next_state_type'].shape[1:]))\n",
    "\n",
    "gen = generator(dataset_path + '/rl_exploration.hdf5')\n",
    "loaded_dataset = tf.data.Dataset.from_generator(gen,\n",
    "                                                (tf.float32, tf.float32, tf.float32, tf.float32, tf.bool, tf.int8, tf.int8),\n",
    "                                                gen.get_tensor_shape())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% h5py: create a generator\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for state, action, reward, next_state, label, state_type, next_state_type in loaded_dataset:\n",
    "    if label[0]:\n",
    "        print(label[0], next_state[0], next_state_type)\n",
    "    if label[1]:\n",
    "        print(label[1], next_state[1], next_state_type)\n",
    "    if state_type[0] == ts.StepType.LAST:\n",
    "        print(\"BAD STATE S0:\", state[0])\n",
    "    if state_type[1] == ts.StepType.LAST:\n",
    "        print(\"BAD STATE S0:\", state[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% detect BAD states\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ts.StepType.FIRST # initial state\n",
    "ts.StepType.LAST # terminal state\n",
    "ts.StepType.MID # normal state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = data.step_type[:, 0] != ts.StepType.LAST\n",
    "x &= data.step_type[:, 1] != ts.StepType.LAST\n",
    "x.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = data.observation[:, :2, :].numpy()\n",
    "z = y[x]\n",
    "z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}