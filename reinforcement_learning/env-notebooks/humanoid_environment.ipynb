{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import imageio\n",
    "import pybullet_envs\n",
    "import PIL.Image\n",
    "import pybullet\n",
    "import pybullet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=320x240 at 0x7F3067629990>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAADwCAIAAAD+Tyo8AAANf0lEQVR4nO2dzXUcuQ6FaZ3ZO4SJwiHM0iFMcuMQ3m4cwktiJgKdF4Hfon0kuburij8AeQF+38qWqoBLEJdkt1qlTz9+/CgAEJOX1QIAoB8MDBAYDAwQGAwMEBgMDBAYDAwQmN++ff/39q+vXz6XUv7z3/89/vf27/P/2t6IAAQgoCbOp7/+/ucyx1Hc7uvNAyIAAXsK+PT6+lqTg6+E+IqUGL4y4Ss/d+Dz6yrDnV9WKQ4lKEFJfYozA18m6PtivUQEIAAB52E//fX3P5cJWr9uEqR+DBGDl1nlYi50yuUR/P418GDowVCGA1s7EGriGmowe6aavB+hT+4x/1albr7VMcF8a6v+fPIauCmQ042luu5ONxYqQAUiVODnEXok7uV3XYNP+66sMOZCR9j8uXg3cEdEc8UIQAACmgTcfxKrUmKHCLKQZTBLIKnTslzswH1SuGbONVJiuGbJNYfvQo+k7A7VnVEzVHdGzVDdGdOH6s44HurwXeiR6E8vO9cx87KnVy657OmV1ISa1Mi7XfbkgxytgaZdqSZSrT4hRKrVJ7rIwx8j+UlxCosABGwo4OI1sF96Lu6+eHxGuPjyyigX/2Lg1ihH1zddLBX86HqCzw9+dD3BP15/b+DxiCPXT0jB9efXC0ra7fqmW87exOrQ1HHLhE5aq6rjFs2BGKrquEVzIMv75JcPcnQMrCNrXyK0oQ1tj7fcfxJrJC53ud4lLo+7ltx19kGOmnzdN5KOdKQbT9f2JlZ93G1vPL93hxvP793hxvN7bW+s2oGdBGneG07w+b0IXnuvd9LnO7BJaKfbNe9dmHpD2SkbrO/22nehL9O7NsrOt7s26863K096/e2HO3BNlEsdg7cjAAEIOI/w5MdI3uMhwm4RRGSkjHD/YHe/xCZBLiOYBGEs5jJMgmQai0mQr4+P1JkvoiZITRydIDVxYpWlJg4j8gtyEqf2t5FmaiKOmhjiyMYxO0I/hh4JhSQkIalG0ui70PWZJoeqjEaoJaEqoxHqMtQTA8+fJ9tossJso8kKWxJNVphttMdQF8/EclUjHs08YIJo5gETRDMP2BTt4gjdFLHIt4t+wFVNs2HAHD1zZmBzQfUxzQN6xESkVcyFIheOuj7m2Wvgjk9i1cQlJjGXx3QKKxWz+TXwSLL5YetjOoWlAlTAtQJVr4FbQxeB+jZFjhW2KTLlbQ3bFHl5ec8+SumXlchzwhI5feSeh9q5CpoZHNkzg4tEdg0+X/b13wc2FEFwgu8QvDX+SPCfr4Fd9bXGlyquWvzQ4r3jhxbfF//6NfBggqbrW+NPSEH85SmIf0KVgQUnNUeK1vikcIofN8WFgQXnck4WBuKaRbNWHVmWD6Tnwe6tOY4gC1nIMpjl+g98T5NinmVaIurWl4i69SX6mKXzXei+xH2J+nLlS9SXi2manKgvV3eitnehB5N13JUyV8pBkWtJrobPQpeM4x/JNTmdfq7J6RhaMf+F/jsS24l0pFNIZ/BQu6eEKFCgjOkHOD9jjgGa/RjpRrfEJUnJKJVxSdLoGXse7P6UWNZdkjRWZy9JGmtCFZL2PJHjJFwroWsXIm+4wVLhprxt70Kbpycveck7krfTwKuGujD1SN6FqTes9lZDfulIs3CEsYprknpP4vbJyFG8I7XXQ+0eWbgurs2+7cDJPiF71Q48vqStXVDXTuTOhPCAbPYaAca/D3zHeOsjAAEIOBFg81TKR5ZXLYeG5QJyaFguwE/Db5XXNZG4XpM1gAm3qRyZjtu9Iy3hpMHggxyPOUZII8PEvcgw1JBSxqfX11cRTUWjUUxkmCgRkaGjRESGiRIrGS8mUkzmRqco40E4PHuQaX6tGr75gxx392eqqZUSeEqyWRbZt3oeqfOWeyTxDaudKp+YotSsJaOYkqJtenZgk92/rB65E2o9KoXajFutSgu39DYDr9Xqp6ckNYwgKT1c1umpNbCgVQw3XkFJaggOTbAh529v1wa2ta6gVQT3XkFJhhiOTs3DxVRSjaoLA2v6JL0qmI/t7jLNxocG1tx4C+5dxw6V1xR2ourJj5F2qEixPqZqNnehaF3IFu1RmMEfN6tPNgLa+kBbH1G0vbx9KYricXY47oZgnyYxfxX5Ju+lOIx8n4kp2d8xvkN8sFu1ys1oL1uN2RxzebudDsQbxmM3slU49MsMH6kZ6p9//F4f0HyoZT977Il+2xgqtDFw5Qi/ff+3MqDHxqs8DYHQt0eJINJqfxo1sPkZowRxrwchRHoQYuCaC82QgTWH9EgUnWDIJo3UaWCPjbdsU3R4JMo0OR05u6V2/j5wX7ITPN6yKkHOZjcCSQ20fjlJ1Vlu1vw+8B2BqlxCtW8sYs2XyDY2728jHRFr2ko0wbHUlmiCl6ud8beRTlg+/lYCHXRdCVeHWJ1Wf9S9NjBmeMNPMMfyN8L129rt7czArsowA8wnXNddOuXQwOEWwhtBZUcknBm8WdJ7Twzst/GeSxmHiU8DHXjH0VZ8b2DXZgpau8L2m4tMffhuYNeN92luQ+IqhyPizqn3Gfaj+Pcncjjle0xpTugjaGjxoZc2b/FzFqD+v43UmskJbwOg/xz0n+Ot3+wX+p8SvfqwnOgG89bvaODopSnBj4hzSFCi0I3qZWDmtQZOEDUkWKn9htDwywyVzGnKHO5iFJXkGEVxGIjxDox7wYM0M24+EEsDBy3BKtIMJM28RxyImYEjDv4Itt9tCdfGNgYON+wTcK8smRrAaiyjBvb+AOYbaQ6cN5INJ9mqN62lx9tgyMDTpm1auydrxHzk64TBEfUbOMoIIRl4+COdBg4xtlZSDmoaKQ8v+i3RY2CmCtbCsv7Gb01XT+7ylDsVwBG3hm9yWcMOnNi9bL/hSNweTUOrNbDyGGKReGiJ10HZ/q99sPuAmGYmt3jitstN7j4J8GD3p+SeFbAld7foPtj9iMTHyxvpB5h+QZzvCLkHux8xv7nTd9sO7NA2J2N8/lC7HYpS9hgmY3RCZJhPduAdprxsM8z5bFJYkWHeGzj9i7QbmwxzHzZZHB+H+W5g78evH7FJ6SEfCn55WSilbHP4gQns00sffzz0skpE2Wzv3WqwWy2Ra+3zspt7t+qt3ditqb5++ez7p1VOEi/Ji3vTs1trLTDwVofJGxsOecO1csmQZxt4YStv2FJ7slWPTTXwhhsR7MZkD88z8Fr3Ltx+Wbbms0/N17yJNRkOz0tYW/ZNDtKTDLzPighQJnp4hoG3PTzDWnZoPHcDb773bj78zVfPCcP3NfDy9t28gSB9BzoaOH3tIAS5+9DLwMurpgBFKCyjpRTPIrgYWKFx6Rt4I3FD2htYoVgAm2BsYBH3Kmy/IqWAGwrT4dGWCT+JpeBe+Agz8oZ5KSwNrLDIARwh0p+2HjYzcMrqdCNSDbhDZF4Mu/T5g91bEbFNyThDg4gUpMjUJFlBDHZgkYkpSnMDsiRr11EDJysHwEzGm3bIwDrulYKyiCM1QYMe7jdwpirABKTmKE33dho4zfgBQtNjYCn3qkFxoiA1U92bUPhPYrH9BoLJOqGvOM0Gllq3AEZQa+YOD7cZOMGAXVGrD1yiNmWtLd1g4OhDBQWYtUuaSlRrYDX3Algh2Nv1Hq4ycOgRAkSkssOvDSzoXk0oVFw0567GwxcGjjswkEVz+jRb/ZIzA2sOSXP6ATy47PZDA2u6VxbKlQDNSTz3cLBPYrH95oB5bOKkXM8NrLkUAXgj2/lHHn5i4HBjWI5sxaAD2dl82v/3Bo6lHmArHl3wi4Fl3Qv5UF6RlY1wV7d3AwcSDbAzH+3w08DK7hWH0qUkyrS+FHmtbL9ZEZ9ZZV+8le5FWWWRn2OAVdysEeyDHGqIL38wiPj8fv3yWdrAbL/pYYoHkTYwwHLEN2FdA+uvzVJT++cfv6+WAAsQNbC+e9X49v3f1RLSIrVS3yFqYNiHEIu1rIcVDRxiRgEUUDRwCGSXZHBCc8blDMz2uyFMejefXl9fV2t4R3ORe0qUnotSUurZh9wOHIIo3QbmqE29kIHV1jYAfYQMDDsTaPmW2oRVDMz8AXQgYeBA7gUoSou4hIEBSrR1XMTD6w3MtAF0s97AAEFRWM0XGzjW9gve0A+trDQwswXRWb4Jc4RuYPlsgSBru2KZgdl+AcZhBwYtIq7sCzfhNQZmkgBMWGDgiO4FOGfV+s4RGuQIusQv8fBsAzM3AIawAwOYMX+hn2rgoNsvgCzzDIx7oZ643TJ5E+YIfQ0vgEGWSQaOu6ACtDJzxWcHBlFCL/rTPDzDwMwEgBPuBg7tXoBu5iz9HKFBF1b/S3wNHH0COD/DCBP6hx0YwBFvDzsaOPr2C6CPl4FxL5iQoJFcN2GO0IfwAhj0cTFwglUTwBC/zYAdGNTJsR84edjewJQbYBrGBs7hXgAPPHYFjtAAgbE0cJrtl/OzGrTWEezAAFOx9bCZgdOskQCBsDFwJvdyftaEHnsKR2iAwBgYONPSCDAHq02YHRjCkGyrMPHwqIGpKcBChgyczL0AkxnfMDhCAwSm38D5tl/Oz/rQdXewAwMsZsTDnQbOtxACRKTHwCndy/k5CrTfRzhCAwSm2cAp1z+A5fRtwv8HOC7cF5vsz68AAAAASUVORK5CYII=\n"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tf_agents.agents.reinforce import reinforce_agent\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from reinforcement_learning.sac_training import NumberOfSafetyViolations\n",
    "env = gym.make('HumanoidBulletEnv-v0')\n",
    "# env.render(mode='human')\n",
    "env.reset()\n",
    "PIL.Image.fromarray(env.render(mode='rgb_array'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "To use the imageio ffmpeg plugin you need to 'pip install imageio-ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/imageio/plugins/ffmpeg.py\u001B[0m in \u001B[0;36m_get_ffmpeg_api\u001B[0;34m()\u001B[0m\n\u001B[1;32m     58\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m             \u001B[0;32mimport\u001B[0m \u001B[0mimageio_ffmpeg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     60\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mImportError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'imageio_ffmpeg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-850fad1d36d0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mdone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mvideo_filename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'humanoid_gym.mp4'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mwith\u001B[0m \u001B[0mimageio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_writer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvideo_filename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m60\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mvideo\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maction_space\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/imageio/core/functions.py\u001B[0m in \u001B[0;36mget_writer\u001B[0;34m(uri, format, mode, **kwargs)\u001B[0m\n\u001B[1;32m    229\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    230\u001B[0m     \u001B[0;31m# Return its writer object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 231\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mformat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_writer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    232\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/imageio/core/format.py\u001B[0m in \u001B[0;36mget_writer\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    183\u001B[0m                 \u001B[0;34m\"Format %s cannot write in %s mode\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    184\u001B[0m             )\n\u001B[0;32m--> 185\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mWriter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    186\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    187\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mcan_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/imageio/core/format.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, format, request)\u001B[0m\n\u001B[1;32m    219\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_request\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m             \u001B[0;31m# Open the reader/writer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 221\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    222\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m         \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/imageio/plugins/ffmpeg.py\u001B[0m in \u001B[0;36m_open\u001B[0;34m(self, fps, codec, bitrate, pixelformat, ffmpeg_params, input_params, output_params, ffmpeg_log_level, quality, macro_block_size)\u001B[0m\n\u001B[1;32m    523\u001B[0m             \u001B[0mmacro_block_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m16\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    524\u001B[0m         ):\n\u001B[0;32m--> 525\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_ffmpeg_api\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_ffmpeg_api\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    526\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_filename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_local_filename\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    527\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pix_fmt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/imageio/plugins/ffmpeg.py\u001B[0m in \u001B[0;36m_get_ffmpeg_api\u001B[0;34m()\u001B[0m\n\u001B[1;32m     60\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mImportError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m             raise ImportError(\n\u001B[0;32m---> 62\u001B[0;31m                 \u001B[0;34m\"To use the imageio ffmpeg plugin you need to \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     63\u001B[0m                 \u001B[0;34m\"'pip install imageio-ffmpeg'\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m             )\n",
      "\u001B[0;31mImportError\u001B[0m: To use the imageio ffmpeg plugin you need to 'pip install imageio-ffmpeg'"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "video_filename = 'humanoid_gym.mp4'\n",
    "with imageio.get_writer(video_filename, fps=60) as video:\n",
    "    while not done:\n",
    "        state, reward, done, info = env.step(env.action_space.sample())\n",
    "        video.append_data(env.render(mode='rgb_array'))\n",
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Pybullet testing environment\n",
    "import PIL.Image\n",
    "import os\n",
    "# Important: pybullet should be charged only once !!\n",
    "from tf_agents.environments import suite_pybullet, parallel_py_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.trajectories.trajectory import Trajectory\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.drivers import dynamic_episode_driver, dynamic_step_driver\n",
    "from tf_agents.policies import random_tf_policy\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001B[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=320x240 at 0x7FC010544C90>",
      "image/png": "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\n"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_env = suite_pybullet.load('HumanoidBulletEnv-v0')\n",
    "py_env.render(mode='human')\n",
    "py_env.reset()\n",
    "PIL.Image.fromarray(py_env.render())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Open Pybullet gui for the humanoid environment\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad state!: 0.7796496152877808\n",
      "bad state!: 0.7732096314430237\n",
      "bad state!: 0.7717272639274597\n",
      "bad state!: 0.7794982194900513\n",
      "bad state!: 0.7793211936950684\n",
      "bad state!: 0.7799262404441833\n",
      "bad state!: 0.7795565128326416\n",
      "bad state!: 0.7799650430679321\n",
      "bad state!: 0.7797608375549316\n",
      "bad state!: 0.7798738479614258\n",
      "bad state!: 0.7577369213104248\n",
      "bad state!: 0.7778942584991455\n",
      "bad state!: 0.7799336910247803\n",
      "bad state!: 0.7666406631469727\n",
      "bad state!: 0.7609941959381104\n"
     ]
    },
    {
     "data": {
      "text/plain": "(TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 44), dtype=float32, numpy=\n array([[ 5.9999996e-01, -1.7949991e-05,  1.0000000e+00,  0.0000000e+00,\n          0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n         -1.2134220e-01,  0.0000000e+00,  4.7853976e-01,  0.0000000e+00,\n          1.2096228e-01,  0.0000000e+00,  7.0311141e-01,  0.0000000e+00,\n          3.5016638e-01,  0.0000000e+00,  6.6564119e-01,  0.0000000e+00,\n          1.0611154e+00,  0.0000000e+00,  6.3744384e-01,  0.0000000e+00,\n          2.0316984e-01,  0.0000000e+00,  7.8265125e-01,  0.0000000e+00,\n          1.0763040e+00,  0.0000000e+00,  1.3847239e-01,  0.0000000e+00,\n          2.4064557e-01,  0.0000000e+00,  2.2795661e-01,  0.0000000e+00,\n         -1.0727448e-01,  0.0000000e+00, -1.7644325e-01,  0.0000000e+00,\n          3.3536100e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n       dtype=float32)>),\n ())"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_state_detection = lambda trajectory: print(\"bad state!: {}\".format(trajectory.observation[0][0] + 0.8))\\\n",
    "    if trajectory.observation[0][0] + 0.8 <= 0.78 else None\n",
    "tf_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "stochastic_policy_dir = '../reinforcement_learning/saves/HumanoidBulletEnv-v0/' \\\n",
    "                        'policy/permissive_variance_policy-multiplier=5.5'\n",
    "policy = tf.compat.v2.saved_model.load(stochastic_policy_dir)\n",
    "dynamic_episode_driver.DynamicEpisodeDriver(tf_env, policy, num_episodes=15, observers=[bad_state_detection]).run()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Perform a few steps in this environment\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001B[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001B[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001B[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001B[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": "TimeStep(step_type=<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 0], dtype=int32)>, reward=<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>, discount=<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>, observation=<tf.Tensor: shape=(4, 44), dtype=float32, numpy=\narray([[ 5.9999996e-01,  9.2012087e-06,  1.0000000e+00,  0.0000000e+00,\n         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n        -8.4347658e-02,  0.0000000e+00,  4.9782762e-01,  0.0000000e+00,\n        -1.5650268e-01,  0.0000000e+00,  6.6706383e-01,  0.0000000e+00,\n         2.7644044e-01,  0.0000000e+00,  7.6475137e-01,  0.0000000e+00,\n         1.0315669e+00,  0.0000000e+00,  3.3479026e-01,  0.0000000e+00,\n         1.8095379e-01,  0.0000000e+00,  7.2646117e-01,  0.0000000e+00,\n         1.0932105e+00,  0.0000000e+00,  2.4763696e-01,  0.0000000e+00,\n         2.5020656e-01,  0.0000000e+00,  2.7137965e-01,  0.0000000e+00,\n        -1.7225973e-01,  0.0000000e+00, -1.7970306e-01,  0.0000000e+00,\n         2.3676927e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n       [ 5.9999996e-01,  9.5833839e-06,  1.0000000e+00,  0.0000000e+00,\n         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n         3.4528080e-02,  0.0000000e+00,  4.5102498e-01,  0.0000000e+00,\n        -1.1036922e-01,  0.0000000e+00,  9.4807583e-01,  0.0000000e+00,\n         1.6237655e-01,  0.0000000e+00,  7.9210973e-01,  0.0000000e+00,\n         1.0460438e+00,  0.0000000e+00,  7.9909235e-01,  0.0000000e+00,\n         3.7631339e-01,  0.0000000e+00,  7.5315362e-01,  0.0000000e+00,\n         1.0317209e+00,  0.0000000e+00,  2.2780815e-01,  0.0000000e+00,\n         1.5281232e-01,  0.0000000e+00,  2.6487377e-01,  0.0000000e+00,\n        -1.3401361e-01,  0.0000000e+00, -2.4237543e-01,  0.0000000e+00,\n         2.3121384e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n       [ 5.9999996e-01, -2.3816108e-05,  1.0000000e+00,  0.0000000e+00,\n         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n         6.2721446e-02,  0.0000000e+00,  3.6126959e-01,  0.0000000e+00,\n         1.6047487e-01,  0.0000000e+00,  1.0007697e+00,  0.0000000e+00,\n         3.3286935e-01,  0.0000000e+00,  6.9328016e-01,  0.0000000e+00,\n         1.0053686e+00,  0.0000000e+00,  7.0983803e-01,  0.0000000e+00,\n         1.5656975e-01,  0.0000000e+00,  6.9104648e-01,  0.0000000e+00,\n         9.5633751e-01,  0.0000000e+00,  1.6178825e-01,  0.0000000e+00,\n         1.8288791e-01,  0.0000000e+00,  2.1966627e-01,  0.0000000e+00,\n        -2.1568698e-01,  0.0000000e+00, -1.9870269e-01,  0.0000000e+00,\n         3.2365960e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n       [ 5.9999996e-01,  1.0410515e-05,  1.0000000e+00,  0.0000000e+00,\n         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n        -6.5628804e-02,  0.0000000e+00,  3.3014318e-01,  0.0000000e+00,\n         1.8770784e-02,  0.0000000e+00,  3.7903500e-01,  0.0000000e+00,\n         2.8580526e-01,  0.0000000e+00,  7.0428425e-01,  0.0000000e+00,\n         9.9776560e-01,  0.0000000e+00,  1.0153058e+00,  0.0000000e+00,\n         1.4491501e-01,  0.0000000e+00,  6.8741292e-01,  0.0000000e+00,\n         1.0239682e+00,  0.0000000e+00,  2.2144526e-01,  0.0000000e+00,\n         1.5595123e-01,  0.0000000e+00,  2.5607449e-01,  0.0000000e+00,\n        -2.1930864e-01,  0.0000000e+00, -2.1139996e-01,  0.0000000e+00,\n         3.5883859e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n      dtype=float32)>)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parallel environments.\n",
    "num_parallel_environments = 4\n",
    "tf_env = tf_py_environment.TFPyEnvironment(parallel_py_environment.ParallelPyEnvironment(\n",
    "    [lambda : suite_pybullet.load('HumanoidBulletEnv-v0')] * num_parallel_environments))\n",
    "tf_env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load a tf parallel environment (4 parallel environments)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/drivers/dynamic_step_driver.py:201: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/florentdelgrange/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/drivers/dynamic_step_driver.py:201: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
     ]
    },
    {
     "data": {
      "text/plain": "(TimeStep(step_type=<tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 1, 1, 1], dtype=int32)>, reward=<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-2.5384243, -0.9994545, -1.3221866, -4.84467  ], dtype=float32)>, discount=<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>, observation=<tf.Tensor: shape=(4, 44), dtype=float32, numpy=\n array([[ 0.41176334, -0.2789402 ,  0.9603085 ,  0.00863498,  0.05806908,\n         -0.759165  , -0.15419166,  0.20408311, -0.7107086 ,  1.1116505 ,\n          0.4178036 , -0.61616814,  0.52912843,  0.2858384 ,  0.9821978 ,\n          0.20272146,  0.22775355, -1.4387232 , -0.30971187, -1.2928632 ,\n         -0.11986443, -2.1810336 ,  0.24825212,  0.0512737 ,  0.94758   ,\n          2.7920022 ,  0.586587  , -0.51935333,  0.78832793, -0.96389645,\n          0.18246822, -0.16469318, -0.21625288, -0.04163652,  0.97070974,\n          1.6089721 , -0.19109546,  0.18365687, -0.6443071 , -0.04858434,\n         -0.67030716,  0.13413754,  0.        ,  0.        ],\n        [ 0.5819433 , -0.18015341,  0.9836385 , -0.00386739,  0.09215581,\n         -0.20065369, -0.02748964,  0.09873738,  0.14364697, -0.50551134,\n          0.39154395, -0.3483388 ,  0.06833222, -0.1238022 , -0.10120953,\n          0.06481649, -0.04406518,  0.37190598,  0.66620636,  0.06517529,\n          1.0015324 , -0.01280546,  0.6502242 , -0.15939632,  0.6734088 ,\n          0.7202818 ,  0.36592352, -0.58697927,  0.56139535, -1.0535014 ,\n          0.17272638, -0.20282632,  0.04594008, -0.9545687 ,  0.746944  ,\n          2.4064178 , -0.13188218, -0.08905131, -0.3580304 , -1.0108019 ,\n         -0.03641676, -0.8371836 ,  0.        ,  0.        ],\n        [ 0.569772  , -0.16540264,  0.98622614, -0.15410551,  0.09743823,\n         -0.1596852 ,  0.01405112,  0.14484507, -0.15579183, -0.13774987,\n          0.33566537, -0.80087376, -0.14742047, -0.05586551,  1.0092245 ,\n         -0.01463615,  0.0251562 , -0.3930289 ,  0.42891222,  1.1527635 ,\n          0.7673651 ,  1.1578506 , -0.03551503, -0.18889971,  0.6395782 ,\n          1.2743524 ,  0.3588861 ,  0.29454622,  0.6147287 , -0.38083652,\n          0.14748162, -0.11431718,  0.1004381 , -0.14620282,  0.693301  ,\n         -0.2896145 , -0.10163181, -0.02880897, -0.37869504, -0.8952869 ,\n         -0.38822475, -2.8991127 ,  0.        ,  0.        ],\n        [ 0.56011045, -0.08019293,  0.9967794 ,  0.20525135, -0.03110231,\n         -0.25836918,  0.08551581,  0.1468296 , -0.37320983, -1.1467016 ,\n          0.0926291 ,  1.1118976 , -0.1521381 , -0.21487407,  0.8550636 ,\n         -0.41479877,  1.0157526 ,  1.6361264 ,  0.60546976, -2.7503505 ,\n          0.49357492, -2.0893953 ,  0.3180121 , -0.5575938 ,  0.05601405,\n         -1.6935468 ,  0.7767818 , -1.9344103 ,  0.79456943, -1.882703  ,\n          0.03137142, -0.08450176,  0.13412966, -0.13175435, -0.5204202 ,\n         -1.7159903 , -0.27819777, -0.23209818, -0.17425418,  0.15953518,\n          0.6952184 ,  0.8951259 ,  0.        ,  0.        ]],\n       dtype=float32)>),\n ())"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer_size = 12800\n",
    "\n",
    "# create a dataset\n",
    "from tf_agents.agents.reinforce import reinforce_agent\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "    tf_env.observation_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    fc_layer_params=(128, 128))\n",
    "policy = random_tf_policy.RandomTFPolicy(tf_env.time_step_spec(), tf_env.action_spec())\n",
    "train_step_counter = tf.compat.v2.Variable(0)\n",
    "\n",
    "agent = reinforce_agent.ReinforceAgent(\n",
    "    tf_env.time_step_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    actor_network=actor_net,\n",
    "    optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4),\n",
    "    normalize_returns=True,\n",
    "    train_step_counter=train_step_counter)\n",
    "agent.initialize()\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=tf_env.batch_size,\n",
    "    max_length=replay_buffer_size)\n",
    "whole_dataset = replay_buffer.as_dataset(num_parallel_calls=3, sample_batch_size=replay_buffer_size, num_steps=3)\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(tf_env.time_step_spec(), tf_env.action_spec())\n",
    "dynamic_step_driver.DynamicStepDriver(tf_env, random_policy,\n",
    "                                      observers=[replay_buffer.add_batch], num_steps=replay_buffer_size).run()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Fill in a replay buffer\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def labeling_function(states):\n",
    "    return states[..., 0] + 0.8 <= 0.78"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% define a labeling function\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-2.4801683, -1.9745685], dtype=float32)>,\n <tf.Tensor: shape=(), dtype=float32, numpy=-2.4801683>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tf_agents.trajectories.time_step as ts\n",
    "\n",
    "scalar_rewards = True\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    num_steps=2,).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "iterator = iter(dataset)\n",
    "raw_data, b = next(iterator)\n",
    "\n",
    "states = raw_data.observation[0, :]\n",
    "actions = raw_data.action[0, :]\n",
    "rewards = raw_data.reward[0]\n",
    "next_states = raw_data.observation[1, :]\n",
    "first_labels = tf.cast(labeling_function(states), tf.float32)\n",
    "next_labels = tf.cast(labeling_function(next_states), tf.float32)\n",
    "labels = tf.cast(labeling_function(raw_data.observation), tf.float32)\n",
    "\n",
    "states, actions, rewards, next_states, first_labels, next_labels, labels\n",
    "raw_data.reward, raw_data.reward[0, ...]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(128, 44), dtype=float32, numpy=\n array([[ 4.7232839e-01, -1.7611326e-01,  9.8436993e-01, ...,\n         -5.0841606e-01,  0.0000000e+00,  0.0000000e+00],\n        [ 1.1732262e-01, -9.6525276e-01,  2.6131800e-01, ...,\n         -1.5835127e+00,  0.0000000e+00,  0.0000000e+00],\n        [ 3.4838113e-01, -6.0660309e-01,  7.9500484e-01, ...,\n         -1.3338916e+00,  0.0000000e+00,  0.0000000e+00],\n        ...,\n        [ 5.9999996e-01, -1.6793409e-05,  1.0000000e+00, ...,\n          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n        [-2.2671875e-02, -1.5902920e-01,  9.8727387e-01, ...,\n          2.0993819e+00,  0.0000000e+00,  1.0000000e+00],\n        [-5.7793405e-02,  6.2928128e-01,  7.7717763e-01, ...,\n         -7.6214999e-01,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>,\n <tf.Tensor: shape=(128, 1), dtype=float32, numpy=\n array([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.]], dtype=float32)>,\n <tf.Tensor: shape=(128, 17), dtype=float32, numpy=\n array([[ 0.56845665, -0.86450577,  0.13716054, ..., -0.8298049 ,\n         -0.59874225,  0.8758371 ],\n        [-0.05417657, -0.7317655 , -0.10691166, ...,  0.13592124,\n         -0.98665166, -0.65903616],\n        [-0.36527157, -0.32092237, -0.1672852 , ..., -0.4601524 ,\n          0.56684375, -0.782861  ],\n        ...,\n        [-0.4833007 , -0.36422825,  0.7621548 , ...,  0.28380108,\n          0.05899239,  0.6232679 ],\n        [-0.8798492 ,  0.0912466 , -0.76804304, ..., -0.52726436,\n         -0.91239786, -0.65833974],\n        [-0.07862568,  0.8131006 , -0.8544729 , ..., -0.22995663,\n          0.4652009 ,  0.40079212]], dtype=float32)>,\n <tf.Tensor: shape=(128,), dtype=float32, numpy=\n array([-3.2513084e+00, -2.0050418e+00, -1.8242197e+00, -1.2467303e+00,\n        -9.1914892e-01,  2.6882872e-01, -2.5151873e+00, -6.3904673e-01,\n        -3.1388061e+00,  5.7574445e-01, -2.2617631e+00, -4.3732185e+00,\n         1.9384037e-01,  5.4716295e-01, -1.5743813e-01, -1.8866397e+00,\n        -2.0727730e-01, -1.0622641e+00, -3.2235036e+00, -1.1826197e+00,\n        -2.5513437e-01, -1.2455647e+00, -5.5131383e+00, -3.7455840e+00,\n        -2.7552447e+00, -6.2087810e-01, -2.0128267e+00, -1.8880409e+00,\n        -2.5168688e+00, -1.3374214e+00,  0.0000000e+00,  5.6229371e-01,\n        -6.3092327e-01, -1.9237379e+00, -4.2431489e-02,  0.0000000e+00,\n        -1.1993414e+00, -2.5041351e-01, -3.2607574e+00, -1.3062420e+00,\n        -1.6473796e+00, -8.6527628e-01, -2.3331411e+00, -3.7037992e+00,\n         0.0000000e+00, -8.9690536e-02, -8.7233764e-01, -4.0425745e-01,\n        -3.0328968e+00, -2.0438676e+00, -1.3683797e+00, -6.1509621e-01,\n        -7.0638394e-01, -5.2290392e-01, -1.1022391e+00, -2.2836065e+00,\n         3.4423572e-01, -2.3184142e-01, -3.4718490e+00, -2.2336974e+00,\n        -3.5871071e-01, -1.3825860e+00, -4.8765919e-01, -2.1909955e+00,\n        -1.3581592e+00, -4.2716556e+00, -3.2199233e+00, -2.4439456e+00,\n        -1.7052802e+00, -1.8118329e+00,  6.7837912e-01, -3.4829111e+00,\n        -1.6431580e+00,  4.5126659e-01, -4.8832607e-01, -9.6416220e-02,\n        -6.1648703e-01, -1.5074278e+00, -1.7190223e+00, -3.3565738e+00,\n        -3.2291107e+00,  1.9959576e-02, -2.0617573e+00, -1.9301929e+00,\n        -1.1022291e+00, -1.7589488e+00, -6.0388291e-01, -1.9070014e+00,\n        -1.9316874e+00, -2.7528219e+00, -4.2685685e-01, -9.2473865e-01,\n         0.0000000e+00, -8.0038536e-01, -1.2777145e+00,  3.6286868e-02,\n        -2.4077861e+00, -1.8401694e+00, -1.1833252e+00, -8.5089219e-01,\n        -1.9635105e+00, -3.0853846e+00,  0.0000000e+00, -1.9476478e+00,\n        -1.1579705e+00, -2.5905702e+00, -2.0392203e+00, -1.1395141e+00,\n        -4.3805131e-01, -2.4393520e+00, -2.6460150e-01, -1.7046460e+00,\n        -3.8686895e+00, -2.7408665e-01, -2.9754126e-01, -8.7202942e-01,\n        -2.4683778e+00, -2.6248353e+00, -9.4283992e-01, -1.7039331e+00,\n        -1.3638760e+00, -5.4664952e-01,  0.0000000e+00, -2.6327267e+00,\n         2.3562826e-04, -1.2436305e+00,  0.0000000e+00,  0.0000000e+00],\n       dtype=float32)>,\n <tf.Tensor: shape=(128, 44), dtype=float32, numpy=\n array([[ 4.2917740e-01, -2.2377700e-01,  9.7464037e-01, ...,\n          8.0399561e-01,  0.0000000e+00,  0.0000000e+00],\n        [ 5.6624759e-02, -9.9058932e-01,  1.3686775e-01, ...,\n         -2.7603176e+00,  0.0000000e+00,  0.0000000e+00],\n        [ 3.1299245e-01, -6.6010517e-01,  7.5117320e-01, ...,\n         -2.5367761e+00,  0.0000000e+00,  0.0000000e+00],\n        ...,\n        [ 5.9799033e-01,  6.3008531e-03,  9.9998015e-01, ...,\n          1.0012149e+00,  0.0000000e+00,  0.0000000e+00],\n        [ 5.9999996e-01,  1.5952533e-05,  1.0000000e+00, ...,\n          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n        [ 5.9999996e-01,  1.1410046e-05,  1.0000000e+00, ...,\n          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>,\n <tf.Tensor: shape=(128, 1), dtype=float32, numpy=\n array([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]], dtype=float32)>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util.io.dataset_generator import map_rl_trajectory_to_vae_input\n",
    "\n",
    "dataset_generator = lambda: replay_buffer.as_dataset(\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    num_steps=2\n",
    ").map(\n",
    "    map_func=lambda trajectory, _: map_rl_trajectory_to_vae_input(trajectory, labeling_function),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    #  deterministic=False  # TF version >= 2.2.0\n",
    ")\n",
    "dataset = dataset_generator().batch(batch_size=128, drop_remainder=True)\n",
    "dataset_iterator = iter(dataset.prefetch(tf.data.experimental.AUTOTUNE))\n",
    "next(dataset_iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "state_type = raw_data.step_type[:2]\n",
    "next_state_type = raw_data.next_step_type[:2]\n",
    "\n",
    "# remove transitions where the incident state is terminal and next state is initial\n",
    "# note: such transitions correspond to those where the reset() function has been called\n",
    "filtering = state_type[0] != ts.StepType.LAST\n",
    "filtering &= state_type[1] != ts.StepType.LAST\n",
    "filtering &= next_state_type[0] != ts.StepType.FIRST\n",
    "filtering &= next_state_type[1] != ts.StepType.FIRST\n",
    "filtering = tf.reduce_all(filtering)\n",
    "\n",
    "print(\"filtering\", filtering)\n",
    "print(\"state_type\", state_type)\n",
    "print(\"next_state_type\", next_state_type)\n",
    "\n",
    "states = raw_data.observation[:2, :]\n",
    "actions = raw_data.action[:2, :]\n",
    "rewards = raw_data.reward[:2] if scalar_rewards else reward[:2, :]\n",
    "if scalar_rewards:\n",
    "    rewards = tf.reshape(rewards, list(rewards.shape) + [1])\n",
    "next_states = raw_data.observation[1:, :]\n",
    "next_labels = labeling_function(next_states)\n",
    "if next_labels.shape == states.shape[:-1]:\n",
    "    next_labels = tf.reshape(next_labels, list(next_labels.shape) + [1])\n",
    "\n",
    "print(\"states\", states)\n",
    "print(\"next_states\", next_states)\n",
    "print(\"rewards\", rewards)\n",
    "print(\"next_labels\", next_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tf_agents.trajectories.time_step as ts\n",
    "import datetime\n",
    "\n",
    "dataset_path = 'dataset'\n",
    "iterator = iter(dataset)\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "with h5py.File(dataset_path + '/rl_exploration' + current_time + '.hdf5', 'w') as h5f:\n",
    "    data = iterator.next()[0]\n",
    "    states = data.observation[:, :2, :].numpy()\n",
    "    actions = data.action[:, :2, :].numpy()\n",
    "    rewards = data.reward[:, :2].numpy()\n",
    "    next_states = data.observation[:, 1:, :].numpy()\n",
    "    next_labels = labeling_function(next_states)\n",
    "    # 0: initial state; 1: mid state; 2: terminal state\n",
    "    state_type = data.step_type[:, :2].numpy()\n",
    "    next_state_type = data.next_step_type[:, :2].numpy()\n",
    "\n",
    "    # remove transitions where the incident state is terminal and next state is initial\n",
    "    filtering = state_type[:, 0] != ts.StepType.LAST\n",
    "    filtering &= state_type[:, 1] != ts.StepType.LAST\n",
    "    filtering &= next_state_type[:, 0] != ts.StepType.FIRST\n",
    "    filtering &= next_state_type[:, 1] != ts.StepType.FIRST\n",
    "\n",
    "    h5f['state'] = states[filtering]\n",
    "    h5f['action'] = actions[filtering]\n",
    "    h5f['reward'] = rewards[filtering]\n",
    "    h5f['next_state'] = next_states[filtering]\n",
    "    h5f['next_state_label'] = next_labels[filtering]\n",
    "    # 0: initial state; 1: mid state; 2: terminal state\n",
    "    h5f['state_type'] = state_type[filtering]\n",
    "    h5f['next_state_type'] = state_type[filtering]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% h5py: store a dataset from the replay memory\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import glob\n",
    "import os\n",
    "\n",
    "file_list: List[str] = glob.glob(os.path.join(dataset_path, 'rl_*')) + \\\n",
    "                       glob.glob(os.path.join(dataset_path, 'reinforcement_learning', 'rl_*'))\n",
    "print(\"File list:\")\n",
    "print(file_list)\n",
    "\n",
    "length: int = 0\n",
    "h5f_indices: Dict[str, Tuple[int, int]] = {}\n",
    "shape: Dict[str, Tuple[int, ...]] = {}\n",
    "dataset_name = 'rl_observation_dataset.hdf5'\n",
    "\n",
    "for h5f_name in file_list:\n",
    "    with h5py.File(h5f_name, 'r') as h5f:\n",
    "        h5f_length = h5f['state'].shape[0]  # we assume that all h5f datasets have the same length (= size of axis 0)\n",
    "        h5f_indices[h5f_name] = (length, length + h5f_length)\n",
    "        length += h5f_length\n",
    "\n",
    "for i, h5f_name in enumerate(file_list):\n",
    "    with h5py.File(h5f_name, 'r') as h5f:\n",
    "        with h5py.File(os.path.join(dataset_path, dataset), 'w') as merged_h5f:\n",
    "            for key in h5f:\n",
    "                if i == 0:  # dataset file initialization\n",
    "                    shape[key] = (length, ) + h5f[key].shape[1:]\n",
    "                    merged_h5f.create_dataset(key, shape[key], dtype=h5f[key].dtype)\n",
    "                first, last = h5f_indices[h5f_name]\n",
    "                merged_h5f[key][first: last] = h5f[key]\n",
    "\n",
    "print(\"Dataset files merged\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% h5py: merge two stored datasets\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class generator:\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "\n",
    "    def __call__(self):\n",
    "        with h5py.File(self.file, 'r') as hf:\n",
    "            for (state, action, reward, next_state, label, state_type, next_state_type) in \\\n",
    "                zip(hf['state'], hf['action'], hf['reward'], hf['next_state'],\n",
    "                    hf['next_state_label'], hf['state_type'], hf['next_state_type']):\n",
    "                yield state, action, reward, next_state, label, state_type, next_state_type\n",
    "\n",
    "    def get_tensor_shape(self):\n",
    "        with h5py.File(self.file, 'r') as hf:\n",
    "           return (tf.TensorShape(hf['state'].shape[1:]),\n",
    "                   tf.TensorShape(hf['action'].shape[1:]),\n",
    "                   tf.TensorShape(hf['reward'].shape[1:]),\n",
    "                   tf.TensorShape(hf['next_state'].shape[1:]),\n",
    "                   tf.TensorShape(hf['next_state_label'].shape[1:]),\n",
    "                   tf.TensorShape(hf['state_type'].shape[1:]),\n",
    "                   tf.TensorShape(hf['next_state_type'].shape[1:]))\n",
    "\n",
    "gen = generator(dataset_path + '/rl_exploration.hdf5')\n",
    "loaded_dataset = tf.data.Dataset.from_generator(gen,\n",
    "                                                (tf.float32, tf.float32, tf.float32, tf.float32, tf.bool, tf.int8, tf.int8),\n",
    "                                                gen.get_tensor_shape())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% h5py: create a generator\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for state, action, reward, next_state, label, state_type, next_state_type in loaded_dataset:\n",
    "    if label[0]:\n",
    "        print(label[0], next_state[0], next_state_type)\n",
    "    if label[1]:\n",
    "        print(label[1], next_state[1], next_state_type)\n",
    "    if state_type[0] == ts.StepType.LAST:\n",
    "        print(\"BAD STATE S0:\", state[0])\n",
    "    if state_type[1] == ts.StepType.LAST:\n",
    "        print(\"BAD STATE S0:\", state[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% detect BAD states\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ts.StepType.FIRST # initial state\n",
    "ts.StepType.LAST # terminal state\n",
    "ts.StepType.MID # normal state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = data.step_type[:, 0] != ts.StepType.LAST\n",
    "x &= data.step_type[:, 1] != ts.StepType.LAST\n",
    "x.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = data.observation[:, :2, :].numpy()\n",
    "z = y[x]\n",
    "z\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from reinforcement_learning import sac_training, labeling_functions\n",
    "\n",
    "learner = sac_training.SACLearner(\n",
    "    env_name='HumanoidBulletEnv-v0',\n",
    "    env_suite=suite_pybullet,\n",
    "    labeling_function=labeling_functions['HumanoidBulletEnv-v0'],\n",
    "    save_directory_location='..'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Create a permissive variance policy\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "variance_multiplier = 2."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learner.save_permissive_variance_policy(variance_multiplier=variance_multiplier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from tf_agents.environments import suite_pybullet, parallel_py_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.drivers import dynamic_episode_driver, dynamic_step_driver\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load and try the permissive variance policy\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "py_env = suite_pybullet.load('HumanoidBulletEnv-v0')\n",
    "py_env.render(mode='human')\n",
    "py_env.reset()\n",
    "tf_env = tf_py_environment.TFPyEnvironment(py_env)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from reinforcement_learning.sac_training import NumberOfSafetyViolations\n",
    "from reinforcement_learning import labeling_functions\n",
    "stochastic_policy_dir = os.path.join(\n",
    "    '..',\n",
    "    'saves',\n",
    "    'HumanoidBulletEnv-v0',\n",
    "    'policy',\n",
    "    \"permissive_variance_policy-multiplier={}\".format(\n",
    "        variance_multiplier)\n",
    ")\n",
    "policy = tf.compat.v2.saved_model.load(stochastic_policy_dir)\n",
    "safety_violations = NumberOfSafetyViolations(\n",
    "    labeling_function=labeling_functions['HumanoidBulletEnv-v0'])\n",
    "\n",
    "dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "    tf_env,\n",
    "    policy,\n",
    "    num_episodes=30,\n",
    "    observers=[\n",
    "        lambda _: py_env.render(mode='human'),\n",
    "        safety_violations\n",
    "    ]\n",
    ").run()\n",
    "\n",
    "print(\"avg number of safety violations per episode\", safety_violations.average())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Before running this cell, load the single py environment\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}