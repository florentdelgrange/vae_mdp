{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import base64\n",
    "import IPython\n",
    "from tf_agents.environments import suite_gym, parallel_py_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer, episodic_replay_buffer\n",
    "from tf_agents.drivers import dynamic_episode_driver, dynamic_step_driver\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')  #  allows testing during training\n",
    "from tf_agents.trajectories import time_step as ts, policy_step, trajectory\n",
    "from reinforcement_learning import labeling_functions\n",
    "labeling_function = labeling_functions['Pendulum-v0']\n",
    "from util.io.dataset_generator import map_rl_trajectory_to_vae_input\n",
    "from util.io.dataset_generator import ErgodicMDPTransitionGenerator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Pendulum-v0 environment\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "TimeStep(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)), observation=BoundedTensorSpec(shape=(3,), dtype=tf.float32, name='observation', minimum=array([-1., -1., -8.], dtype=float32), maximum=array([1., 1., 8.], dtype=float32)))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_env = suite_gym.load('Pendulum-v0')\n",
    "py_env.reset()\n",
    "tf_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "tf_env.time_step_spec()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def display_safe_labeling(trajectory):\n",
    "    label = labeling_functions['Pendulum-v0'](trajectory.observation)\n",
    "    if tf.reduce_any(label):\n",
    "        print(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Perform a few steps in this environment\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "replay_buffer_capacity = 1280\n",
    "# specs\n",
    "action_spec = tf_env.action_spec()\n",
    "policy_step_spec = policy_step.PolicyStep(\n",
    "    action=action_spec,\n",
    "    state=(),\n",
    "    info=())\n",
    "trajectory_spec = trajectory.from_transition(tf_env.time_step_spec(),\n",
    "                                             policy_step_spec,\n",
    "                                             tf_env.time_step_spec())\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=trajectory_spec,\n",
    "    batch_size=tf_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)\n",
    "\n",
    "dataset_generator = lambda: replay_buffer.as_dataset(\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    num_steps=2\n",
    ").map(\n",
    "    map_func=lambda trajectory, _: map_rl_trajectory_to_vae_input(trajectory, labeling_function),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    #  deterministic=False  # TF version >= 2.2.0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(TimeStep(step_type=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>, reward=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>, discount=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>, observation=<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-0.95974445,  0.2808747 , -0.7560645 ]], dtype=float32)>),\n ())"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "\n",
    "sac_policy_dir = '../saves/Pendulum-v0/policy/permissive_variance_policy-multiplier=15.0'\n",
    "policy = tf.compat.v2.saved_model.load(sac_policy_dir)\n",
    "dynamic_episode_driver.DynamicEpisodeDriver(tf_env, policy, num_episodes=5,\n",
    "                                            observers=[\n",
    "                                                # display_safe_labeling,\n",
    "                                                lambda _: py_env.render(mode='human'),\n",
    "                                                replay_buffer.add_batch\n",
    "                                            ]).run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "state tf.Tensor([ 0.9263725  -0.3766085  -0.22603792], shape=(3,), dtype=float32)\n",
      "\n",
      "labels tf.Tensor(\n",
      "[[1. 1. 0.]\n",
      " [1. 1. 0.]], shape=(2, 3), dtype=float32)\n",
      "\n",
      "label tf.Tensor([1. 1. 0.], shape=(3,), dtype=float32)\n",
      "\n",
      "action tf.Tensor([0.06637995], shape=(1,), dtype=float32)\n",
      "\n",
      "reward tf.Tensor(-0.15421203, shape=(), dtype=float32)\n",
      "\n",
      "next_state tf.Tensor([ 0.91669804 -0.3995807  -0.4985373 ], shape=(3,), dtype=float32)\n",
      "\n",
      "next_label tf.Tensor([1. 1. 0.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    num_steps=2\n",
    ")\n",
    "iterator = iter(dataset)\n",
    "trajectory, _ = next(iterator)\n",
    "\n",
    "state = trajectory.observation[0, ...]\n",
    "labels = tf.cast(labeling_function(trajectory.observation), tf.float32)\n",
    "if tf.rank(labels) == 1:\n",
    "    labels = tf.expand_dims(labels, axis=-1)\n",
    "label = labels[0, ...]\n",
    "action = trajectory.action[0, ...]\n",
    "reward = trajectory.reward[0, ...]\n",
    "if tf.rank(reward) == 1:\n",
    "    reward = tf.expand_dims(reward, axis=-1)\n",
    "next_state = trajectory.observation[1, ...]\n",
    "next_label = labels[1, ...]\n",
    "\n",
    "print(\"\\nstate\", state)\n",
    "print('\\nlabels', labels)\n",
    "print('\\nlabel', label)\n",
    "print('\\naction', action)\n",
    "print('\\nreward', reward)\n",
    "print('\\nnext_state', next_state)\n",
    "print('\\nnext_label', next_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n array([[ 6.4294201e-01, -7.6591486e-01, -1.5775427e+00],\n        [ 9.6671438e-01, -2.5585803e-01,  8.1465445e-02],\n        [-7.7596229e-01, -6.3077927e-01,  6.2149205e+00],\n        [ 9.4504619e-01,  3.2693693e-01,  9.9686503e-02],\n        [ 9.7825205e-01,  2.0741959e-01, -3.3456117e-03],\n        [ 9.1297662e-01,  4.0801185e-01,  2.7977255e-01],\n        [ 9.5500523e-01,  2.9658905e-01, -1.6795512e-01],\n        [ 9.6319401e-01,  2.6880711e-01,  2.4182208e-01]], dtype=float32)>,\n <tf.Tensor: shape=(8, 4), dtype=float32, numpy=\n array([[1., 0., 0., 0.],\n        [1., 1., 1., 0.],\n        [0., 0., 0., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 0., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.]], dtype=float32)>,\n <tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n array([[ 1.955008 ],\n        [ 1.5483292],\n        [ 0.9434242],\n        [-1.9972148],\n        [-1.9793999],\n        [-0.299812 ],\n        [-1.9335557],\n        [-1.8219309]], dtype=float32)>,\n <tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n array([[-1.013878  ],\n        [-0.07000488],\n        [-9.91027   ],\n        [-0.11591195],\n        [-0.04757358],\n        [-0.18454853],\n        [-0.09723218],\n        [-0.08323521]], dtype=float32)>,\n <tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n array([[ 0.56908846, -0.8222763 , -1.8587276 ],\n        [ 0.96825486, -0.24996501,  0.1218213 ],\n        [-0.5597398 , -0.8286684 ,  5.88335   ],\n        [ 0.9443031 ,  0.32907695,  0.04530699],\n        [ 0.979727  ,  0.20033702, -0.1446909 ],\n        [ 0.9016114 ,  0.432547  ,  0.54080963],\n        [ 0.9584319 ,  0.28532133, -0.2355467 ],\n        [ 0.9608725 ,  0.27699107,  0.17013778]], dtype=float32)>,\n <tf.Tensor: shape=(8, 4), dtype=float32, numpy=\n array([[1., 0., 0., 0.],\n        [1., 1., 1., 0.],\n        [0., 0., 0., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 0., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.]], dtype=float32)>)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = ErgodicMDPTransitionGenerator(labeling_function, replay_buffer)\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=4,\n",
    "    num_steps=2\n",
    ").map(\n",
    "    map_func=generator,\n",
    "    num_parallel_calls=4,\n",
    "    #  deterministic=False  # TF version >= 2.2.0\n",
    ").batch(batch_size=8, drop_remainder=True)\n",
    "iterator = iter(dataset)\n",
    "next(iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Importing a function (__inference_entropy_regularizer_81377) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_entropy_regularizer_81377) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_entropy_regularizer_81377) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_82873) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_82873) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_82873) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_82652) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_82652) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_82652) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88731) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88731) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88731) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_90141) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_90141) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_90141) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88799) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88799) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88799) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "VAE MDP loaded\n",
      "TimeStep(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)), observation=BoundedTensorSpec(shape=(12,), dtype=tf.int32, name='observation', minimum=array(0, dtype=int32), maximum=array(1, dtype=int32))) BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32))\n",
      "avg rewards tf.Tensor(-673.27014, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import variational_action_discretizer\n",
    "\n",
    "vae_mdp = variational_action_discretizer.load(\n",
    "    # \"../../saves/Pendulum-v0/models/vae_LS12_MC1_ER20.0-decay=7.5e-05-min=-10_KLA0.0-growth=1e-06_TD0.70-0.50_1e-06-2e-06/policy/action_discretizer/LA3_MC1_ER20.0-decay=7.5e-05-min=-10_KLA0.0-growth=1e-06_TD0.50-0.33_1e-06-2e-06_params=full_vae_optimization/step140000/eval_elbo-3.784\"\n",
    "    # \"../../saves/Pendulum-v0/models/vae_LS13_MC1_ER20.0-decay=2e-05-min=-10_KLA0.0-growth=1e-06_TD0.70-0.50_1e-06-2e-06/policy/action_discretizer/LA5_MC1_ER20.0-decay=2e-05-min=-10_KLA0.0-growth=1e-06_TD0.25-0.17_1e-06-2e-06_params=full_vae_optimization/step270000/eval_elbo-1.704\"\n",
    "    # \"../../saves/Pendulum-v0/models/vae_LS13_MC1_ER20.0-decay=7.5e-05-min=-10_KLA0.0-growth=1e-06_TD0.70-0.50_1e-06-2e-06/permissive_variance_policy-multiplier=10.0/action_discretizer/LA5_MC1_ER20.0-decay=7.5e-05-min=-10_KLA0.0-growth=1e-06_TD0.25-0.17_1e-06-2e-06_params=full_vae_optimization/step70000/eval_elbo-7.265\"\n",
    "    # \"../../saves/Pendulum-v0/models/vae_LS12_MC3_CER100.0-decay=1e-05_KLA1e-06-growth=1e-07_TD0.95-0.90_1e-06-2e-06/policy/action_discretizer/LA3_MC3_CER100.0-decay=1e-05_KLA1e-06-growth=1e-07_TD0.50-0.33_1e-06-2e-06_params=full_vae_optimization/step1010000/eval_elbo11.174\"\n",
    "    # '../../saves/Pendulum-v0/models/vae_LS12_MC1_ER20.0-decay=7.5e-05-min=-10_KLA0.0-growth=1e-06_TD0.95-0.90_1e-06-2e-06/policy/action_discretizer/LA3_MC1_ER20.0-decay=7.5e-05-min=-10_KLA0.0-growth=1e-06_TD0.50-0.33_1e-06-2e-06_params=full_vae_optimization/step1010000/eval_elbo-2.888'\n",
    "    # '../../saves/Pendulum-v0/models/vae_LS12_MC1_ER10.0-decay=0.0001-min=0_KLA0.0-growth=5e-06_TD0.70-0.57_2e-06-1e-06_seed=290321/policy/action_discretizer/LA3_MC1_ER10.0-decay=0.0001-min=0_KLA0.0-growth=5e-06_TD0.50-0.33_2e-06-1e-06_params=full_vae_optimization-relaxed_state_encoding/step360000/eval_elbo4.516'\n",
    "    '../../saves/Pendulum-v0/models/vae_LS12_MC1_ER10.0-decay=7.5e-05-min=0_KLA0.0-growth=5e-05_TD0.67-0.50_1e-06-2e-06_seed=20421/policy/action_discretizer/LA3_MC1_ER10.0-decay=7.5e-05-min=0_KLA0.0-growth=5e-05_TD0.50-0.33_1e-06-2e-06_params=full_vae_optimization-relaxed_state_encoding/base',\n",
    "    step=1830000\n",
    ")\n",
    "print(\"VAE MDP loaded\")\n",
    "\n",
    "discrete_tf_env = vae_mdp.wrap_tf_environment(\n",
    "    tf_env=tf_env,\n",
    "    labeling_function=labeling_function,\n",
    "    deterministic_embedding_functions=True\n",
    ")\n",
    "discrete_tf_env.reset()\n",
    "print(discrete_tf_env.time_step_spec(), discrete_tf_env.action_spec())\n",
    "\n",
    "reward_metric = tf_metrics.AverageReturnMetric()\n",
    "\n",
    "policy = vae_mdp.get_latent_policy()\n",
    "\n",
    "dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "    discrete_tf_env,\n",
    "    policy,\n",
    "    num_episodes=30,\n",
    "    observers=[\n",
    "        lambda _: py_env.render(mode='human'),\n",
    "        reward_metric\n",
    "    ]\n",
    ").run()\n",
    "\n",
    "print(\"avg rewards\", reward_metric.result())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_2801669) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_2801669) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_2801669) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_entropy_regularizer_159182) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_entropy_regularizer_159182) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_entropy_regularizer_159182) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_2796026) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_2796026) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_2796026) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_compute_loss_2801460) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_compute_loss_2801460) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_compute_loss_2801460) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_compute_loss_2801460) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_compute_loss_2801460) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_compute_loss_2801460) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_2801737) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_2801737) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_2801737) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_2803033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_2803033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_2803033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__forward_entropy_regularizer_160711) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__forward_entropy_regularizer_160711) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__forward_entropy_regularizer_160711) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_2795805) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_2795805) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:tensorflow:Importing a function (__inference__wrapped_model_2795805) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "name = '../../saves/Pendulum-v0/models/vae_LS12_MC1_ER10.0-decay=0.0001-min=0_KLA0.0-growth=5e-06_TD0.70-0.57_2e-06-1e-06_seed=290321/policy/action_discretizer/LA3_MC1_ER10.0-decay=0.0001-min=0_KLA0.0-growth=5e-06_TD0.50-0.33_2e-06-1e-06_params=full_vae_optimization-relaxed_state_encoding/step350000/eval_elbo4.750'\n",
    "model = tf.saved_model.load(name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.saved_model.function_deserialization.RestoredFunction at 0x7fe14fb9d810>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import imageio\n",
    "import IPython\n",
    "\n",
    "def embed_mp4(filename):\n",
    "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "  video = open(filename,'rb').read()\n",
    "  b64 = base64.b64encode(video)\n",
    "  tag = '''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "  return IPython.display.HTML(tag)\n",
    "\n",
    "def create_policy_eval_video(policy, py_env, tf_env, filename, num_episodes=5, fps=30):\n",
    "  filename = filename + \".mp4\"\n",
    "  with imageio.get_writer(filename, fps=fps) as video:\n",
    "    for _ in range(num_episodes):\n",
    "      time_step = tf_env.reset()\n",
    "      print(py_env.render(mode='rgb_array'))\n",
    "      video.append_data(py_env.render(mode='rgb_array'))\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = tf_env.step(action_step.action)\n",
    "        video.append_data(py_env.render(mode='rgb_array'))\n",
    "  return embed_mp4(filename)\n",
    "\n",
    "create_policy_eval_video(policy, py_env, tf_env, 'pendulum-latent-policy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}