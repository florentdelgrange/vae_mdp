{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import os\n",
    "import tf_agents.policies\n",
    "import tf_agents.specs\n",
    "from tf_agents.environments import suite_gym, parallel_py_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.policies.tf_py_policy import TFPyPolicy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer, episodic_replay_buffer\n",
    "from tf_agents.drivers import dynamic_episode_driver, dynamic_step_driver\n",
    "import tensorflow as tf\n",
    "from tf_agents.trajectories.policy_step import PolicyStep\n",
    "tf.config.set_visible_devices([], 'GPU')  #  allows testing during training\n",
    "from tf_agents.trajectories import time_step as ts, policy_step, trajectory\n",
    "from reinforcement_learning import labeling_functions\n",
    "labeling_function = labeling_functions['LunarLanderContinuous-v2']\n",
    "from util.io.dataset_generator import map_rl_trajectory_to_vae_input\n",
    "from util.io.dataset_generator import ErgodicMDPTransitionGenerator\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% LunarLanderContinuous-v2\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "TimeStep(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)), observation=BoundedTensorSpec(shape=(8,), dtype=tf.float32, name='observation', minimum=array(-3.4028235e+38, dtype=float32), maximum=array(3.4028235e+38, dtype=float32)))"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_env = suite_gym.load('LunarLanderContinuous-v2')\n",
    "py_env.reset()\n",
    "tf_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "tf_env.time_step_spec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "tf_env = tf_py_environment.TFPyEnvironment(py_env)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "replay_buffer_capacity = 1280\n",
    "# specs\n",
    "policy_step_spec =  policy_step.PolicyStep(\n",
    "    action=tf_env.action_spec(),\n",
    "    state=(),\n",
    "    info=())\n",
    "trajectory_spec = trajectory.from_transition(tf_env.time_step_spec(),\n",
    "                                             policy_step_spec,\n",
    "                                             tf_env.time_step_spec())\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=trajectory_spec,\n",
    "    batch_size=tf_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)\n",
    "\n",
    "dataset_generator = lambda: replay_buffer.as_dataset(\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    num_steps=2\n",
    ").map(\n",
    "    map_func=lambda trajectory, _: map_rl_trajectory_to_vae_input(trajectory, labeling_function),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    #  deterministic=False  # TF version >= 2.2.0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "class SavedTFPolicy(tf_agents.policies.tf_policy.Base):\n",
    "\n",
    "    def __init__(self, saved_policy_path, time_step_spec):\n",
    "        self.saved_policy = tf.compat.v2.saved_model.load(sac_policy_dir)\n",
    "        spec_path = os.path.join(saved_policy_path, policy_saver.COLLECT_POLICY_SPEC)\n",
    "        policy_specs = tf_agents.specs.tensor_spec.from_pbtxt_file(spec_path)\n",
    "        super().__init__(\n",
    "            time_step_spec,\n",
    "            action_spec=policy_specs['collect_data_spec'].action,\n",
    "            info_spec=policy_specs['collect_data_spec'].policy_info,\n",
    "            policy_state_spec=policy_specs['policy_state_spec'])\n",
    "\n",
    "    def _action(self, time_step, policy_state, seed):\n",
    "        return self.saved_policy.action(time_step, policy_state, seed)\n",
    "\n",
    "    def _distribution(self, time_step, policy_state):\n",
    "        policy_step = self._action(time_step, policy_state, None)\n",
    "        return PolicyStep(tfd.Deterministic(policy_step.action), policy_step.state, policy_step.info)\n",
    "\n",
    "    def _get_initial_state(self, batch_size):\n",
    "        return self.saved_policy.get_initial_state(batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find matching function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * TimeStep(step_type=<tf.Tensor 'time_step:0' shape=(1,) dtype=int32>, reward=<tf.Tensor 'time_step_1:0' shape=(1,) dtype=float32>, discount=<tf.Tensor 'time_step_2:0' shape=(1,) dtype=float32>, observation=<tf.Tensor 'time_step_3:0' shape=(1, 8) dtype=float32>)\n    * ()\n    * None\n  Keyword arguments: {}\n\nExpected these arguments to match one of the following 2 option(s):\n\nOption 1:\n  Positional arguments (2 total):\n    * TimeStep(step_type=TensorSpec(shape=(None,), dtype=tf.int32, name='time_step/step_type'), reward=TensorSpec(shape=(None,), dtype=tf.float32, name='time_step/reward'), discount=TensorSpec(shape=(None,), dtype=tf.float32, name='time_step/discount'), observation=TensorSpec(shape=(None, 8), dtype=tf.float32, name='time_step/observation'))\n    * ()\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (2 total):\n    * TimeStep(step_type=TensorSpec(shape=(None,), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(None,), dtype=tf.float32, name='reward'), discount=TensorSpec(shape=(None,), dtype=tf.float32, name='discount'), observation=TensorSpec(shape=(None, 8), dtype=tf.float32, name='observation'))\n    * ()\n  Keyword arguments: {}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-80-8ee15bfea2ad>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m                                                 \u001B[0;32mlambda\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mpy_env\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrender\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'human'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m                                                 \u001B[0mreplay_buffer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_batch\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m                                                 \u001B[0mreward_metric\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m                                             ]).run()\n\u001B[1;32m     24\u001B[0m \u001B[0mreward_metric\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/drivers/dynamic_episode_driver.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self, time_step, policy_state, num_episodes, maximum_iterations)\u001B[0m\n\u001B[1;32m    191\u001B[0m         \u001B[0mpolicy_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpolicy_state\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    192\u001B[0m         \u001B[0mnum_episodes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_episodes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 193\u001B[0;31m         maximum_iterations=maximum_iterations)\n\u001B[0m\u001B[1;32m    194\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    195\u001B[0m   def _run(self,\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/utils/common.py\u001B[0m in \u001B[0;36mwith_check_resource_vars\u001B[0;34m(*fn_args, **fn_kwargs)\u001B[0m\n\u001B[1;32m    183\u001B[0m         \u001B[0;31m# We're either in eager mode or in tf.function mode (no in-between); so\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    184\u001B[0m         \u001B[0;31m# autodep-like behavior is already expected of fn.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 185\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfn_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfn_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    186\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mresource_variables_enabled\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    187\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mMISSING_RESOURCE_VARIABLES_ERROR\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/drivers/dynamic_episode_driver.py\u001B[0m in \u001B[0;36m_run\u001B[0;34m(self, time_step, policy_state, num_episodes, maximum_iterations)\u001B[0m\n\u001B[1;32m    220\u001B[0m             \u001B[0mparallel_iterations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m             \u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 222\u001B[0;31m             name='driver_loop'))\n\u001B[0m\u001B[1;32m    223\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001B[0m in \u001B[0;36mnew_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    572\u001B[0m                   \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__module__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'in a future version'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    573\u001B[0m                   if date is None else ('after %s' % date), instructions)\n\u001B[0;32m--> 574\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    575\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    576\u001B[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop_v2\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001B[0m\n\u001B[1;32m   2489\u001B[0m       \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2490\u001B[0m       \u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmaximum_iterations\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2491\u001B[0;31m       return_same_structure=True)\n\u001B[0m\u001B[1;32m   2492\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2493\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001B[0m in \u001B[0;36mwhile_loop\u001B[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001B[0m\n\u001B[1;32m   2725\u001B[0m                                               list(loop_vars))\n\u001B[1;32m   2726\u001B[0m       \u001B[0;32mwhile\u001B[0m \u001B[0mcond\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2727\u001B[0;31m         \u001B[0mloop_vars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbody\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2728\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtry_to_pack\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloop_vars\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_basetuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2729\u001B[0m           \u001B[0mpacked\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/drivers/dynamic_episode_driver.py\u001B[0m in \u001B[0;36mloop_body\u001B[0;34m(counter, time_step, policy_state)\u001B[0m\n\u001B[1;32m    120\u001B[0m         \u001B[0mloop_vars\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mnext\u001B[0m \u001B[0miteration\u001B[0m \u001B[0mof\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhile_loop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    121\u001B[0m       \"\"\"\n\u001B[0;32m--> 122\u001B[0;31m       \u001B[0maction_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpolicy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m       \u001B[0;31m# TODO(b/134487572): TF2 while_loop seems to either ignore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/policies/tf_policy.py\u001B[0m in \u001B[0;36maction\u001B[0;34m(self, time_step, policy_state, seed)\u001B[0m\n\u001B[1;32m    277\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_automatic_state_reset\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    278\u001B[0m       \u001B[0mpolicy_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_reset_state\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 279\u001B[0;31m     \u001B[0mstep\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maction_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpolicy_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseed\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    280\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    281\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclip_action\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maction_spec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/utils/common.py\u001B[0m in \u001B[0;36mwith_check_resource_vars\u001B[0;34m(*fn_args, **fn_kwargs)\u001B[0m\n\u001B[1;32m    183\u001B[0m         \u001B[0;31m# We're either in eager mode or in tf.function mode (no in-between); so\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    184\u001B[0m         \u001B[0;31m# autodep-like behavior is already expected of fn.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 185\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfn_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfn_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    186\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mresource_variables_enabled\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    187\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mMISSING_RESOURCE_VARIABLES_ERROR\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/policies/epsilon_greedy_policy.py\u001B[0m in \u001B[0;36m_action\u001B[0;34m(self, time_step, policy_state, seed)\u001B[0m\n\u001B[1;32m     90\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_action\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     91\u001B[0m     \u001B[0mseed_stream\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSeedStream\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msalt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'epsilon_greedy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 92\u001B[0;31m     \u001B[0mgreedy_action\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_greedy_policy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     93\u001B[0m     \u001B[0mrandom_action\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_random_policy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseed_stream\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/policies/tf_policy.py\u001B[0m in \u001B[0;36maction\u001B[0;34m(self, time_step, policy_state, seed)\u001B[0m\n\u001B[1;32m    277\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_automatic_state_reset\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    278\u001B[0m       \u001B[0mpolicy_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_reset_state\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 279\u001B[0;31m     \u001B[0mstep\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maction_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpolicy_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseed\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    280\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    281\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclip_action\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maction_spec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/utils/common.py\u001B[0m in \u001B[0;36mwith_check_resource_vars\u001B[0;34m(*fn_args, **fn_kwargs)\u001B[0m\n\u001B[1;32m    183\u001B[0m         \u001B[0;31m# We're either in eager mode or in tf.function mode (no in-between); so\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    184\u001B[0m         \u001B[0;31m# autodep-like behavior is already expected of fn.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 185\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfn_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfn_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    186\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mresource_variables_enabled\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    187\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mMISSING_RESOURCE_VARIABLES_ERROR\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/policies/tf_policy.py\u001B[0m in \u001B[0;36m_action\u001B[0;34m(self, time_step, policy_state, seed)\u001B[0m\n\u001B[1;32m    477\u001B[0m     \"\"\"\n\u001B[1;32m    478\u001B[0m     \u001B[0mseed_stream\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSeedStream\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msalt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'ppo_policy'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 479\u001B[0;31m     \u001B[0mdistribution_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_distribution\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    480\u001B[0m     actions = tf.nest.map_structure(\n\u001B[1;32m    481\u001B[0m         \u001B[0;32mlambda\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mreparameterized_sampling\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseed\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mseed_stream\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/policies/greedy_policy.py\u001B[0m in \u001B[0;36m_distribution\u001B[0;34m(self, time_step, policy_state)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m     distribution_step = self._wrapped_policy.distribution(\n\u001B[0;32m---> 77\u001B[0;31m         time_step, policy_state)\n\u001B[0m\u001B[1;32m     78\u001B[0m     return policy_step.PolicyStep(\n\u001B[1;32m     79\u001B[0m         \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdist_fn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdistribution_step\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tf_agents/policies/tf_policy.py\u001B[0m in \u001B[0;36mdistribution\u001B[0;34m(self, time_step, policy_state)\u001B[0m\n\u001B[1;32m    327\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_automatic_state_reset\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m       \u001B[0mpolicy_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_reset_state\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 329\u001B[0;31m     \u001B[0mstep\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_distribution\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpolicy_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    330\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0memit_log_probability\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    331\u001B[0m       \u001B[0;31m# This here is set only for compatibility with info_spec in constructor.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-79-bb5f08e20ecf>\u001B[0m in \u001B[0;36m_distribution\u001B[0;34m(self, time_step, policy_state)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_distribution\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m         \u001B[0mpolicy_step\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_action\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mPolicyStep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtfd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDeterministic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpolicy_step\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_step\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_step\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-79-bb5f08e20ecf>\u001B[0m in \u001B[0;36m_action\u001B[0;34m(self, time_step, policy_state, seed)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_action\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msaved_policy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_distribution\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicy_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    578\u001B[0m         \u001B[0mxla_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mExit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    579\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 580\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    581\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    582\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mtracing_count\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    625\u001B[0m       \u001B[0;31m# This is the first call of __call__, so we have to initialize.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    626\u001B[0m       \u001B[0minitializers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 627\u001B[0;31m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_initialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madd_initializers_to\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitializers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    628\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    629\u001B[0m       \u001B[0;31m# At this point we know that the initialization is complete (or less\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_initialize\u001B[0;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[1;32m    504\u001B[0m     self._concrete_stateful_fn = (\n\u001B[1;32m    505\u001B[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001B[0;32m--> 506\u001B[0;31m             *args, **kwds))\n\u001B[0m\u001B[1;32m    507\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    508\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minvalid_creator_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0munused_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0munused_kwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_get_concrete_function_internal_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2444\u001B[0m       \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2445\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2446\u001B[0;31m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2447\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2448\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   2775\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2776\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2777\u001B[0;31m       \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2778\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2779\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   2665\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2666\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2667\u001B[0;31m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[1;32m   2668\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2669\u001B[0m         \u001B[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    979\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    980\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 981\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    982\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    983\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    439\u001B[0m         \u001B[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    440\u001B[0m         \u001B[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 441\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    442\u001B[0m     \u001B[0mweak_wrapped_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweakref\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mref\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwrapped_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/vae-mdp/lib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py\u001B[0m in \u001B[0;36mrestored_function_body\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    259\u001B[0m         .format(_pretty_format_positional(args), kwargs,\n\u001B[1;32m    260\u001B[0m                 \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msaved_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcrete_functions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 261\u001B[0;31m                 \"\\n\\n\".join(signature_descriptions)))\n\u001B[0m\u001B[1;32m    262\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    263\u001B[0m   \u001B[0mconcrete_function_objects\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Could not find matching function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * TimeStep(step_type=<tf.Tensor 'time_step:0' shape=(1,) dtype=int32>, reward=<tf.Tensor 'time_step_1:0' shape=(1,) dtype=float32>, discount=<tf.Tensor 'time_step_2:0' shape=(1,) dtype=float32>, observation=<tf.Tensor 'time_step_3:0' shape=(1, 8) dtype=float32>)\n    * ()\n    * None\n  Keyword arguments: {}\n\nExpected these arguments to match one of the following 2 option(s):\n\nOption 1:\n  Positional arguments (2 total):\n    * TimeStep(step_type=TensorSpec(shape=(None,), dtype=tf.int32, name='time_step/step_type'), reward=TensorSpec(shape=(None,), dtype=tf.float32, name='time_step/reward'), discount=TensorSpec(shape=(None,), dtype=tf.float32, name='time_step/discount'), observation=TensorSpec(shape=(None, 8), dtype=tf.float32, name='time_step/observation'))\n    * ()\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (2 total):\n    * TimeStep(step_type=TensorSpec(shape=(None,), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(None,), dtype=tf.float32, name='reward'), discount=TensorSpec(shape=(None,), dtype=tf.float32, name='discount'), observation=TensorSpec(shape=(None, 8), dtype=tf.float32, name='observation'))\n    * ()\n  Keyword arguments: {}"
     ]
    }
   ],
   "source": [
    "def display_labeling(trajectory):\n",
    "    label = labeling_functions['LunarLanderContinuous-v2'](trajectory.observation)\n",
    "    if tf.reduce_any(label[..., 2]) and tf.reduce_any(label[..., 6]):\n",
    "        print('close to the lunar pad with high speed')\n",
    "    if not tf.reduce_any(label[..., 7]):\n",
    "        print('unsafe lander angle')\n",
    "    if tf.reduce_any(label[..., 2]) and not tf.reduce_any(label[..., 8]):\n",
    "        print('close to the lunar pad with unsafe lander angle')\n",
    "    if tf.reduce_any(label[..., 1]):\n",
    "        print('lander too close to the edge of the frame')\n",
    "\n",
    "reward_metric = tf_metrics.AverageReturnMetric()\n",
    "sac_policy_dir = '../saves/LunarLanderContinuous-v2/policy'\n",
    "saved_policy = SavedTFPolicy(sac_policy_dir, tf_env.time_step_spec())\n",
    "policy = tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy(\n",
    "    policy=saved_policy, epsilon=0.8)\n",
    "dynamic_episode_driver.DynamicEpisodeDriver(tf_env, policy, num_episodes=10,\n",
    "                                            observers=[\n",
    "                                                display_labeling,\n",
    "                                                lambda _: py_env.render(mode='human'),\n",
    "                                                replay_buffer.add_batch,\n",
    "                                                reward_metric\n",
    "                                            ]).run()\n",
    "reward_metric.result()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "state tf.Tensor(\n",
      "[ 2.0307970e-01 -3.0652525e-02  4.9495837e-04 -8.7643275e-05\n",
      " -2.1808341e-01 -2.3761325e-04  1.0000000e+00  1.0000000e+00], shape=(8,), dtype=float32)\n",
      "\n",
      "labels tf.Tensor(\n",
      "[[0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1.]], shape=(2, 12), dtype=float32)\n",
      "\n",
      "label tf.Tensor([0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1.], shape=(12,), dtype=float32)\n",
      "\n",
      "action tf.Tensor([-0.6755788 -0.9982296], shape=(2,), dtype=float32)\n",
      "\n",
      "reward tf.Tensor(-0.26637262, shape=(), dtype=float32)\n",
      "\n",
      "next_state tf.Tensor(\n",
      "[ 2.0305118e-01 -3.0642977e-02 -2.9163966e-03  4.3257177e-04\n",
      " -2.1803164e-01  1.0132857e-03  1.0000000e+00  1.0000000e+00], shape=(8,), dtype=float32)\n",
      "\n",
      "next_label tf.Tensor([0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1.], shape=(12,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    num_steps=2\n",
    ")\n",
    "iterator = iter(dataset)\n",
    "trajectory, _ = next(iterator)\n",
    "\n",
    "state = trajectory.observation[0, ...]\n",
    "labels = tf.cast(labeling_function(trajectory.observation), tf.float32)\n",
    "if tf.rank(labels) == 1:\n",
    "    labels = tf.expand_dims(labels, axis=-1)\n",
    "label = labels[0, ...]\n",
    "action = tf.cast(trajectory.action[0, ...], dtype=tf.float32)\n",
    "reward = trajectory.reward[0, ...]\n",
    "if tf.rank(reward) == 1:\n",
    "    reward = tf.expand_dims(reward, axis=-1)\n",
    "next_state = trajectory.observation[1, ...]\n",
    "next_label = labels[1, ...]\n",
    "\n",
    "print(\"\\nstate\", state)\n",
    "print('\\nlabels', labels)\n",
    "print('\\nlabel', label)\n",
    "print('\\naction', action)\n",
    "print('\\nreward', reward)\n",
    "print('\\nnext_state', next_state)\n",
    "print('\\nnext_label', next_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = ErgodicMDPTransitionGenerator(labeling_function, replay_buffer)\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=4,\n",
    "    num_steps=2\n",
    ").map(\n",
    "    map_func=generator,\n",
    "    num_parallel_calls=4,\n",
    "    #  deterministic=False  # TF version >= 2.2.0\n",
    ").batch(batch_size=8, drop_remainder=True)\n",
    "iterator = iter(dataset)\n",
    "next(iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import variational_action_discretizer\n",
    "\n",
    "vae_mdp = variational_action_discretizer.load(\n",
    "    # \"../../saves/Pendulum-v0/models/vae_LS12_MC1_ER20.0-decay=7.5e-05-min=-10_KLA0.0-growth=1e-06_TD0.70-0.50_1e-06-2e-06/policy/action_discretizer/LA3_MC1_ER20.0-decay=7.5e-05-min=-10_KLA0.0-growth=1e-06_TD0.50-0.33_1e-06-2e-06_params=full_vae_optimization/step140000/eval_elbo-3.784\"\n",
    "    # \"../../saves/Pendulum-v0/models/vae_LS13_MC1_ER20.0-decay=2e-05-min=-10_KLA0.0-growth=1e-06_TD0.70-0.50_1e-06-2e-06/policy/action_discretizer/LA5_MC1_ER20.0-decay=2e-05-min=-10_KLA0.0-growth=1e-06_TD0.25-0.17_1e-06-2e-06_params=full_vae_optimization/step270000/eval_elbo-1.704\"\n",
    "    # \"../../saves/Pendulum-v0/models/vae_LS13_MC1_ER20.0-decay=7.5e-05-min=-10_KLA0.0-growth=1e-06_TD0.70-0.50_1e-06-2e-06/permissive_variance_policy-multiplier=10.0/action_discretizer/LA5_MC1_ER20.0-decay=7.5e-05-min=-10_KLA0.0-growth=1e-06_TD0.25-0.17_1e-06-2e-06_params=full_vae_optimization/step70000/eval_elbo-7.265\"\n",
    "    \"../../saves/Pendulum-v0/models/vae_LS12_MC3_CER100.0-decay=1e-05_KLA1e-06-growth=1e-07_TD0.95-0.90_1e-06-2e-06/policy/action_discretizer/LA3_MC3_CER100.0-decay=1e-05_KLA1e-06-growth=1e-07_TD0.50-0.33_1e-06-2e-06_params=full_vae_optimization/step1010000/eval_elbo11.174\"\n",
    ")\n",
    "print(\"VAE MDP loaded\")\n",
    "\n",
    "discrete_tf_env = vae_mdp.wrap_tf_environment(\n",
    "    tf_env=tf_env,\n",
    "    labeling_function=labeling_functions['Pendulum-v0'],\n",
    "    deterministic_embedding_functions=True\n",
    ")\n",
    "discrete_tf_env.reset()\n",
    "\n",
    "reward_metric = tf_metrics.AverageReturnMetric()\n",
    "\n",
    "policy = vae_mdp.get_abstract_policy()\n",
    "\n",
    "dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "    discrete_tf_env,\n",
    "    policy,\n",
    "    num_episodes=20,\n",
    "    observers=[\n",
    "        lambda _: py_env.render(mode='human'),\n",
    "        reward_metric\n",
    "    ]\n",
    ").run()\n",
    "\n",
    "print(\"avg rewards\", reward_metric.result())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}