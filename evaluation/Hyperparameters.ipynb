{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "sys.path.insert(0, path + '/../')\n",
    "\n",
    "from util.io import log_files\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={\"figure.dpi\":150, 'savefig.dpi':300})\n",
    "sns.set_context('paper')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_keys = ['batch_size', 'activation', 'epsilon_greedy','optimizer', 'learning_rate',\n",
    "                       'priority_exponent', 'action_entropy_regularizer_scaling', 'buckets_based_priority',\n",
    "                       'collect_steps_per_iteration', 'importance_sampling_exponent_growth_rate',\n",
    "                       'importance_sampling_exponent',  'prioritized_experience_replay',\n",
    "                       'epsilon_greedy_decay_rate', 'latent_size',\n",
    "                       'relaxed_state_encoder_temperature',\n",
    "                       'relaxed_state_prior_temperature',\n",
    "                       'encoder_temperature', 'prior_temperature', \n",
    "                       'encoder_temperature_decay_rate',\n",
    "                       'prior_temperature_decay_rate', 'entropy_regularizer_scale_factor',\n",
    "                       'entropy_regularizer_decay_rate', 'kl_annealing_scale_factor', 'kl_annealing_growth_rate',\n",
    "                       'start_annealing_step', 'number_of_discrete_actions', ]\n",
    "\n",
    "def map_key(key):\n",
    "    key = key.replace(\"_\", \" \")\n",
    "    filters = {\n",
    "        'latent size': r'$\\left| \\latentstates \\right|$',\n",
    "        'epsilon greedy': r'$\\varepsilon$',\n",
    "        'relaxed state encoder temperature': r'$\\temperature_{1}^{\\scriptscriptstyle \\latentstates}$',\n",
    "        'relaxed state prior temperature': r'$\\temperature_{2}^{\\scriptscriptstyle \\latentstates}$',\n",
    "        'encoder temperature': r'$\\temperature_{1}^{\\scriptscriptstyle \\latentactions}$',\n",
    "        'prior temperature': r'$\\temperature_{2}^{\\scriptscriptstyle \\latentactions}$',\n",
    "        'encoder temperature decay rate': r'$\\tau_{\\temperature_{1}}$',\n",
    "        'prior temperature decay rate': r'$\\tau_{\\temperature_{2}}$',\n",
    "        'entropy regularizer scale factor': '$' + r'\\alpha$',\n",
    "        'entropy regularizer decay rate': r'$\\tau_{' + r'\\alpha}$',\n",
    "        'kl annealing scale factor': r'$\\beta$',\n",
    "        'kl annealing growth rate': r'$\\tau_{\\beta}$',\n",
    "        'number of discrete actions': r'$\\left| \\latentactions \\right|$',\n",
    "        'epsilon greedy decay rate': r'$\\tau_{' + r'\\varepsilon}$',\n",
    "        'importance sampling exponent': r'$\\omega$',\n",
    "        'importance sampling exponent growth rate': r'$\\tau_{\\omega}$',\n",
    "        'buckets based priority': 'bucket based',\n",
    "        'action entropy regularizer scaling': '$' + r'\\alpha_2$'}\n",
    "    return key.replace(key, filters.get(key, key))\n",
    "\n",
    "def map_value(value):\n",
    "    if value == 'leaky_relu':\n",
    "        value = 'leaky relu'\n",
    "    return value\n",
    "\n",
    "df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CartPole-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = json.loads('{\"logtostderr\": false, \"alsologtostderr\": false, \"log_dir\": \"\", \"v\": 0, \"verbosity\": 0, \"logger_levels\": {}, \"stderrthreshold\": \"fatal\", \"showprefixforinfo\": true, \"run_with_pdb\": false, \"pdb_post_mortem\": false, \"pdb\": false, \"run_with_profiling\": false, \"profile_file\": null, \"use_cprofile_for_profiling\": true, \"only_check_args\": false, \"op_conversion_fallback_to_while_loop\": true, \"runtime_oom_exit\": true, \"hbm_oom_exit\": true, \"test_random_seed\": 301, \"test_srcdir\": \"\", \"test_tmpdir\": \"/local/4071978-3.master01.hydra.brussel.vsc/absl_testing\", \"test_randomize_ordering_seed\": \"\", \"xml_output_file\": \"\", \"batch_size\": 128, \"mixture_components\": 1, \"action_mixture_components\": 0, \"full_covariance\": false, \"activation\": \"leaky_relu\", \"latent_size\": 9, \"max_state_decoder_variance\": 0.0, \"encoder_temperature\": 0.99, \"prior_temperature\": 0.95, \"relaxed_state_encoder_temperature\": 0.67, \"relaxed_state_prior_temperature\": 0.5, \"latent_policy\": true, \"encoder_temperature_decay_rate\": 1e-06, \"prior_temperature_decay_rate\": 2e-06, \"entropy_regularizer_scale_factor\": 10.0, \"entropy_regularizer_decay_rate\": 1e-05, \"entropy_regularizer_scale_factor_min_value\": 0.0, \"marginal_entropy_regularizer_ratio\": 0.0, \"kl_annealing_scale_factor\": 0.0, \"kl_annealing_growth_rate\": 5e-05, \"start_annealing_step\": 10000, \"max_steps\": 1500000, \"save_dir\": \"/theia/data/brussel/102/vsc10293/vae_mdp/\", \"logdir\": \"/theia/data/brussel/102/vsc10293/vae_mdp/log/2021-08-25\", \"display_progressbar\": false, \"action_discretizer\": false, \"one_output_per_action\": false, \"do_not_eval\": false, \"full_vae_optimization\": true, \"relaxed_state_encoding\": true, \"number_of_discrete_actions\": 16, \"load_vae\": \"\", \"encoder_layers\": [256, 256], \"decoder_layers\": [256, 256], \"transition_layers\": [256, 256], \"label_transition_layers\": [256, 256], \"reward_layers\": [256, 256], \"discrete_policy_layers\": [256, 256], \"policy_path\": \"/data/brussel/102/vsc10293/rl_policies/CartPole-v0/policy\", \"environment\": \"CartPole-v0\", \"env_suite\": \"suite_gym\", \"policy_environment\": null, \"parallel_env\": 8, \"annealing_period\": 1, \"aggressive_training\": false, \"initial_collect_steps\": 10000, \"seed\": 22222222, \"logs\": true, \"checkpoint\": true, \"epsilon_greedy\": 0.0, \"epsilon_greedy_decay_rate\": 5e-06, \"decompose_training\": false, \"prioritized_experience_replay\": true, \"priority_exponent\": 0.33, \"importance_sampling_exponent\": 0.4, \"importance_sampling_exponent_growth_rate\": 7e-05, \"buckets_based_priority\": true, \"collect_steps_per_iteration\": 16, \"hyperparameter_search\": false, \"hyperparameter_search_trials\": 1, \"prune_trials\": false, \"evaluation_window_size\": 1, \"wall_time\": \".\", \"memory\": -1.0, \"time_stacked_states\": 1, \"state_encoder_pre_processing_network\": false, \"state_encoder_pre_processing_layers\": [256, 256], \"state_decoder_pre_processing_network\": false, \"state_decoder_pre_processing_layers\": [256, 256], \"optimizer\": \"Adam\", \"learning_rate\": 0.001, \"local_losses_evaluation\": true, \"local_losses_evaluation_steps\": 34000, \"local_losses_replay_buffer_size\": 200000, \"evaluation_interval\": 10000, \"label_transition_function\": true, \"action_entropy_regularizer_scaling\": 1.0, \"reward_upper_bound\": null, \"reward_lower_bound\": null, \"generate_videos\": false, \"?\": false, \"help\": false, \"helpshort\": false, \"helpfull\": false, \"helpxml\": false}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = dict((map_key(key), map_value(value)) for key, value in params.items() if key in hyperparameter_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch size': 128,\n",
       " 'activation': 'leaky relu',\n",
       " '$\\\\left| \\\\latentstates \\\\right|$': 9,\n",
       " '$\\\\temperature_{1}^{\\\\scriptscriptstyle \\\\latentactions}$': 0.99,\n",
       " '$\\\\temperature_{2}^{\\\\scriptscriptstyle \\\\latentactions}$': 0.95,\n",
       " '$\\\\temperature_{1}^{\\\\scriptscriptstyle \\\\latentstates}$': 0.67,\n",
       " '$\\\\temperature_{2}^{\\\\scriptscriptstyle \\\\latentstates}$': 0.5,\n",
       " '$\\\\tau_{\\\\temperature_{1}}$': 1e-06,\n",
       " '$\\\\tau_{\\\\temperature_{2}}$': 2e-06,\n",
       " '$\\\\alpha$': 10.0,\n",
       " '$\\\\tau_{\\\\alpha}$': 1e-05,\n",
       " '$\\\\beta$': 0.0,\n",
       " '$\\\\tau_{\\\\beta}$': 5e-05,\n",
       " 'start annealing step': 10000,\n",
       " '$\\\\left| \\\\latentactions \\\\right|$': 16,\n",
       " '$\\\\varepsilon$': 0.0,\n",
       " '$\\\\tau_{\\\\varepsilon}$': 5e-06,\n",
       " 'prioritized experience replay': True,\n",
       " 'priority exponent': 0.33,\n",
       " '$\\\\omega$': 0.4,\n",
       " '$\\\\tau_{\\\\omega}$': 7e-05,\n",
       " 'bucket based': True,\n",
       " 'collect steps per iteration': 16,\n",
       " 'optimizer': 'Adam',\n",
       " 'learning rate': 0.001,\n",
       " '$\\\\alpha_2$': 1.0}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch size': 128,\n",
       " 'activation': 'leaky relu',\n",
       " '$\\\\left| \\\\latentstates \\\\right|$': 9,\n",
       " '$\\\\temperature_{1}^{\\\\scriptscriptstyle \\\\latentactions}$': 0.99,\n",
       " '$\\\\temperature_{2}^{\\\\scriptscriptstyle \\\\latentactions}$': 0.95,\n",
       " '$\\\\temperature_{1}^{\\\\scriptscriptstyle \\\\latentstates}$': 0.67,\n",
       " '$\\\\temperature_{2}^{\\\\scriptscriptstyle \\\\latentstates}$': 0.5,\n",
       " '$\\\\tau_{\\\\temperature_{1}}$': 1e-06,\n",
       " '$\\\\tau_{\\\\temperature_{2}}$': 2e-06,\n",
       " '$\\\\alpha$': 10.0,\n",
       " '$\\\\tau_{\\\\alpha}$': 1e-05,\n",
       " '$\\\\beta$': 0.0,\n",
       " '$\\\\tau_{\\\\beta}$': 5e-05,\n",
       " 'start annealing step': 10000,\n",
       " '$\\\\left| \\\\latentactions \\\\right|$': 16,\n",
       " '$\\\\varepsilon$': 0.0,\n",
       " '$\\\\tau_{\\\\varepsilon}$': 5e-06,\n",
       " 'prioritized experience replay': True,\n",
       " 'priority exponent': 0.33,\n",
       " '$\\\\omega$': 0.4,\n",
       " '$\\\\tau_{\\\\omega}$': 7e-05,\n",
       " 'bucket based': True,\n",
       " 'collect steps per iteration': 16,\n",
       " 'optimizer': 'Adam',\n",
       " 'learning rate': 0.001,\n",
       " '$\\\\alpha_2$': 1.0,\n",
       " 'layers': 2,\n",
       " 'neurons': 256}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = None\n",
    "neurons = None\n",
    "for i in ['encoder', 'decoder', 'transition', 'label_transition', 'reward', 'discrete_policy']:\n",
    "    if layers is None and neurons is None:\n",
    "        layers = len(params[i + '_layers'])\n",
    "        neurons = params[i + '_layers'][0]\n",
    "    assert(layers == len(params[i + '_layers']))\n",
    "    for layer in params[i + '_layers']:\n",
    "        assert(layer == neurons)\n",
    "\n",
    "hyperparameters['layers'] = layers\n",
    "hyperparameters['neurons'] = neurons\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CartPole</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>batch size</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation</th>\n",
       "      <td>leaky relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\left| \\latentstates \\right|$</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\temperature_{1}^{\\scriptscriptstyle \\latentactions}$</th>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\temperature_{2}^{\\scriptscriptstyle \\latentactions}$</th>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\temperature_{1}^{\\scriptscriptstyle \\latentstates}$</th>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\temperature_{2}^{\\scriptscriptstyle \\latentstates}$</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\tau_{\\temperature_{1}}$</th>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\tau_{\\temperature_{2}}$</th>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\alpha$</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\tau_{\\alpha}$</th>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\beta$</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\tau_{\\beta}$</th>\n",
       "      <td>0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start annealing step</th>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\left| \\latentactions \\right|$</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\varepsilon$</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\tau_{\\varepsilon}$</th>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prioritized experience replay</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priority exponent</th>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\omega$</th>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\tau_{\\omega}$</th>\n",
       "      <td>0.00007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bucket based</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect steps per iteration</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer</th>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning rate</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\alpha_2$</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neurons</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          CartPole\n",
       "batch size                                              128       \n",
       "activation                                              leaky relu\n",
       "$\\left| \\latentstates \\right|$                          9         \n",
       "$\\temperature_{1}^{\\scriptscriptstyle \\latentactions}$  0.99      \n",
       "$\\temperature_{2}^{\\scriptscriptstyle \\latentactions}$  0.95      \n",
       "$\\temperature_{1}^{\\scriptscriptstyle \\latentstates}$   0.67      \n",
       "$\\temperature_{2}^{\\scriptscriptstyle \\latentstates}$   0.5       \n",
       "$\\tau_{\\temperature_{1}}$                               0.000001  \n",
       "$\\tau_{\\temperature_{2}}$                               0.000002  \n",
       "$\\alpha$                                                10.0      \n",
       "$\\tau_{\\alpha}$                                         0.00001   \n",
       "$\\beta$                                                 0.0       \n",
       "$\\tau_{\\beta}$                                          0.00005   \n",
       "start annealing step                                    10000     \n",
       "$\\left| \\latentactions \\right|$                         16        \n",
       "$\\varepsilon$                                           0.0       \n",
       "$\\tau_{\\varepsilon}$                                    0.000005  \n",
       "prioritized experience replay                           True      \n",
       "priority exponent                                       0.33      \n",
       "$\\omega$                                                0.4       \n",
       "$\\tau_{\\omega}$                                         0.00007   \n",
       "bucket based                                            True      \n",
       "collect steps per iteration                             16        \n",
       "optimizer                                               Adam      \n",
       "learning rate                                           0.001     \n",
       "$\\alpha_2$                                              1.0       \n",
       "layers                                                  2         \n",
       "neurons                                                 256       "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = 'CartPole'\n",
    "\n",
    "if df is None:\n",
    "    df = pd.DataFrame(hyperparameters, index=[env_name]).transpose()\n",
    "else:\n",
    "    df = pd.concat([df, pd.DataFrame(hyperparameters, index=[env_name]).transpose()], axis=1)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acrobot-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CartPole</th>\n",
       "      <th>Acrobot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>batch size</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation</th>\n",
       "      <td>leaky relu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\left| \\latentstates \\right|$</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\temperature_{1}^{\\scriptscriptstyle \\latentactions}$</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\temperature_{2}^{\\scriptscriptstyle \\latentactions}$</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\temperature_{1}^{\\scriptscriptstyle \\latentstates}$</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\temperature_{2}^{\\scriptscriptstyle \\latentstates}$</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\tau_{\\temperature_{1}}$</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\tau_{\\temperature_{2}}$</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\alpha$</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\tau_{\\alpha}$</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\beta$</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\tau_{\\beta}$</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start annealing step</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\left| \\latentactions \\right|$</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\varepsilon$</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\tau_{\\varepsilon}$</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prioritized experience replay</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priority exponent</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\omega$</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\tau_{\\omega}$</th>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bucket based</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collect steps per iteration</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer</th>\n",
       "      <td>Adam</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning rate</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\alpha_2$</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neurons</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          CartPole   Acrobot\n",
       "batch size                                              128         128     \n",
       "activation                                              leaky relu  relu    \n",
       "$\\left| \\latentstates \\right|$                          9           13      \n",
       "$\\temperature_{1}^{\\scriptscriptstyle \\latentactions}$  0.99        0.99    \n",
       "$\\temperature_{2}^{\\scriptscriptstyle \\latentactions}$  0.95        0.95    \n",
       "$\\temperature_{1}^{\\scriptscriptstyle \\latentstates}$   0.67        0.667   \n",
       "$\\temperature_{2}^{\\scriptscriptstyle \\latentstates}$   0.5         0.5     \n",
       "$\\tau_{\\temperature_{1}}$                               0.000001    0.000001\n",
       "$\\tau_{\\temperature_{2}}$                               0.000002    0.000002\n",
       "$\\alpha$                                                10.0        10.0    \n",
       "$\\tau_{\\alpha}$                                         0.00001     0.000075\n",
       "$\\beta$                                                 0.0         0.0     \n",
       "$\\tau_{\\beta}$                                          0.00005     0.000075\n",
       "start annealing step                                    10000       10000   \n",
       "$\\left| \\latentactions \\right|$                         16          16      \n",
       "$\\varepsilon$                                           0.0         0.5     \n",
       "$\\tau_{\\varepsilon}$                                    0.000005    0.00001 \n",
       "prioritized experience replay                           True        True    \n",
       "priority exponent                                       0.33        0.3     \n",
       "$\\omega$                                                0.4         0.4     \n",
       "$\\tau_{\\omega}$                                         0.00007     0.00007 \n",
       "bucket based                                            True        True    \n",
       "collect steps per iteration                             16          16      \n",
       "optimizer                                               Adam        Adam    \n",
       "learning rate                                           0.001       0.0001  \n",
       "$\\alpha_2$                                              1.0         1.0     \n",
       "layers                                                  2           2       \n",
       "neurons                                                 256         256     "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = json.loads('{\"logtostderr\": false, \"alsologtostderr\": false, \"log_dir\": \"\", \"v\": 0, \"verbosity\": 0, \"logger_levels\": {}, \"stderrthreshold\": \"fatal\", \"showprefixforinfo\": true, \"run_with_pdb\": false, \"pdb_post_mortem\": false, \"pdb\": false, \"run_with_profiling\": false, \"profile_file\": null, \"use_cprofile_for_profiling\": true, \"only_check_args\": false, \"op_conversion_fallback_to_while_loop\": true, \"runtime_oom_exit\": true, \"hbm_oom_exit\": true, \"test_random_seed\": 301, \"test_srcdir\": \"\", \"test_tmpdir\": \"/local/4071980-1.master01.hydra.brussel.vsc/absl_testing\", \"test_randomize_ordering_seed\": \"\", \"xml_output_file\": \"\", \"batch_size\": 128, \"mixture_components\": 1, \"action_mixture_components\": 0, \"full_covariance\": false, \"activation\": \"relu\", \"latent_size\": 13, \"max_state_decoder_variance\": 0.0, \"encoder_temperature\": 0.99, \"prior_temperature\": 0.95, \"relaxed_state_encoder_temperature\": 0.667, \"relaxed_state_prior_temperature\": 0.5, \"latent_policy\": true, \"encoder_temperature_decay_rate\": 1e-06, \"prior_temperature_decay_rate\": 2e-06, \"entropy_regularizer_scale_factor\": 10.0, \"entropy_regularizer_decay_rate\": 7.5e-05, \"entropy_regularizer_scale_factor_min_value\": 0.0, \"marginal_entropy_regularizer_ratio\": 0.0, \"kl_annealing_scale_factor\": 0.0, \"kl_annealing_growth_rate\": 7.5e-05, \"start_annealing_step\": 10000, \"max_steps\": 1500000, \"save_dir\": \"/theia/data/brussel/102/vsc10293/vae_mdp/\", \"logdir\": \"/theia/data/brussel/102/vsc10293/vae_mdp/log/2021-08-25\", \"display_progressbar\": false, \"action_discretizer\": false, \"one_output_per_action\": false, \"do_not_eval\": false, \"full_vae_optimization\": true, \"relaxed_state_encoding\": true, \"number_of_discrete_actions\": 16, \"load_vae\": \"\", \"encoder_layers\": [256, 256], \"decoder_layers\": [256, 256], \"transition_layers\": [256, 256], \"label_transition_layers\": [256, 256], \"reward_layers\": [256, 256], \"discrete_policy_layers\": [256, 256], \"policy_path\": \"reinforcement_learning/saves/AcrobotRandomInit-v1/dqn_policy\", \"environment\": \"Acrobot-v1\", \"env_suite\": \"suite_gym\", \"policy_environment\": \"Acrobot-v1\", \"parallel_env\": 8, \"annealing_period\": 1, \"aggressive_training\": false, \"initial_collect_steps\": 10000, \"seed\": 11111, \"logs\": true, \"checkpoint\": true, \"epsilon_greedy\": 0.5, \"epsilon_greedy_decay_rate\": 1e-05, \"decompose_training\": false, \"prioritized_experience_replay\": true, \"priority_exponent\": 0.3, \"importance_sampling_exponent\": 0.4, \"importance_sampling_exponent_growth_rate\": 7e-05, \"buckets_based_priority\": true, \"collect_steps_per_iteration\": 16, \"hyperparameter_search\": false, \"hyperparameter_search_trials\": 1, \"prune_trials\": false, \"evaluation_window_size\": 1, \"wall_time\": \".\", \"memory\": -1.0, \"time_stacked_states\": 1, \"state_encoder_pre_processing_network\": false, \"state_encoder_pre_processing_layers\": [256, 256], \"state_decoder_pre_processing_network\": false, \"state_decoder_pre_processing_layers\": [256, 256], \"optimizer\": \"Adam\", \"learning_rate\": 0.0001, \"local_losses_evaluation\": true, \"local_losses_evaluation_steps\": 34000, \"local_losses_replay_buffer_size\": 200000, \"evaluation_interval\": 10000, \"label_transition_function\": true, \"action_entropy_regularizer_scaling\": 1.0, \"reward_upper_bound\": null, \"reward_lower_bound\": null, \"generate_videos\": false, \"?\": false, \"help\": false, \"helpshort\": false, \"helpfull\": false, \"helpxml\": false}')\n",
    "hyperparameters = dict((map_key(key), value) for key, value in params.items() if key in hyperparameter_keys)\n",
    "layers = None\n",
    "neurons = None\n",
    "for i in ['encoder', 'decoder', 'transition', 'label_transition', 'reward', 'discrete_policy']:\n",
    "    if layers is None and neurons is None:\n",
    "        layers = len(params[i + '_layers'])\n",
    "        neurons = params[i + '_layers'][0]\n",
    "    assert(layers == len(params[i + '_layers']))\n",
    "    for layer in params[i + '_layers']:\n",
    "        assert(layer == neurons)\n",
    "\n",
    "hyperparameters['layers'] = layers\n",
    "hyperparameters['neurons'] = neurons\n",
    "\n",
    "env_name = 'Acrobot'\n",
    "\n",
    "if df is None:\n",
    "    df = pd.DataFrame(hyperparameters, index=[env_name]).transpose()\n",
    "else:\n",
    "    df = pd.concat([df, pd.DataFrame(hyperparameters, index=[env_name]).transpose()], axis=1)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for environment in df.columns:\n",
    "    if df[df.index == 'prioritized experience replay'][environment].all():\n",
    "        if df[df.index == 'bucket based'][environment].all():\n",
    "            df.loc['prioritized experience replay', environment] = 'buckets'\n",
    "        else:\n",
    "            df.loc['prioritized experience replay', environment] = 'loss'\n",
    "    else:\n",
    "        df.loc['prioritized experience replay', environment] = 'uniform'\n",
    "df = df.drop(index='bucket based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_table = ['batch size', 'activation', 'layers', 'neurons', 'optimizer',\n",
    "              'learning rate', 'collect steps per iteration',\n",
    "              '$\\\\left| \\\\latentstates \\\\right|$',\n",
    "              '$\\\\left| \\\\latentactions \\\\right|$',\n",
    "              '$\\\\temperature_{1}^{\\\\scriptscriptstyle \\\\latentstates}$',\n",
    "              '$\\\\temperature_{2}^{\\\\scriptscriptstyle \\\\latentstates}$',\n",
    "              '$\\\\temperature_{1}^{\\\\scriptscriptstyle \\\\latentactions}$',\n",
    "              '$\\\\temperature_{2}^{\\\\scriptscriptstyle \\\\latentactions}$',\n",
    "              '$\\\\tau_{\\\\temperature_{1}}$',\n",
    "              '$\\\\tau_{\\\\temperature_{2}}$',\n",
    "              '$\\\\alpha$', '$\\\\alpha_2$', '$\\\\tau_{\\\\alpha}$',\n",
    "              '$\\\\beta$', '$\\\\tau_{\\\\beta}$',\n",
    "              'prioritized experience replay',\n",
    "              'priority exponent',\n",
    "              '$\\\\omega$',\n",
    "              '$\\\\tau_{\\\\omega}$'\n",
    "              ]\n",
    "def sort(key):\n",
    "    if key in sort_table:\n",
    "        return sort_table.index(key)\n",
    "    else:\n",
    "        return len(sort_table)\n",
    "\n",
    "df = df.sort_index(key=lambda x: list(map(sort, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} &    CartPole &   Acrobot \\\\\n",
      "\\midrule\n",
      "batch size                                             &  128 &  128 \\\\\n",
      "activation                                             &  leaky relu &  relu \\\\\n",
      "layers                                                 &  2 &  2 \\\\\n",
      "neurons                                                &  256 &  256 \\\\\n",
      "optimizer                                              &  Adam &  Adam \\\\\n",
      "learning rate                                          & $0.001$ & $0.0001$ \\\\\n",
      "collect steps per iteration                            &  16 &  16 \\\\\n",
      "$\\left| \\latentstates \\right|$                         &  9 &  13 \\\\\n",
      "$\\left| \\latentactions \\right|$                        &  16 &  16 \\\\\n",
      "$\\temperature_{1}^{\\scriptscriptstyle \\latentstates}$  & $0.67$ & $0.67$ \\\\\n",
      "$\\temperature_{2}^{\\scriptscriptstyle \\latentstates}$  & $0.5$ & $0.5$ \\\\\n",
      "$\\temperature_{1}^{\\scriptscriptstyle \\latentactions}$ & $0.99$ & $0.99$ \\\\\n",
      "$\\temperature_{2}^{\\scriptscriptstyle \\latentactions}$ & $0.95$ & $0.95$ \\\\\n",
      "$\\tau_{\\temperature_{1}}$                              & $1e-06$ & $1e-06$ \\\\\n",
      "$\\tau_{\\temperature_{2}}$                              & $2e-06$ & $2e-06$ \\\\\n",
      "$\\alpha$                                               & $10$ & $10$ \\\\\n",
      "$\\alpha_2$                                             & $1$ & $1$ \\\\\n",
      "$\\tau_{\\alpha}$                                        & $1e-05$ & $7.5e-05$ \\\\\n",
      "$\\beta$                                                & $0$ & $0$ \\\\\n",
      "$\\tau_{\\beta}$                                         & $5e-05$ & $7.5e-05$ \\\\\n",
      "prioritized experience replay                          &  buckets &  buckets \\\\\n",
      "priority exponent                                      & $0.33$ & $0.3$ \\\\\n",
      "$\\omega$                                               & $0.4$ & $0.4$ \\\\\n",
      "$\\tau_{\\omega}$                                        & $7e-05$ & $7e-05$ \\\\\n",
      "$\\varepsilon$                                          & $0$ & $0.5$ \\\\\n",
      "$\\tau_{\\varepsilon}$                                   & $5e-06$ & $1e-05$ \\\\\n",
      "start annealing step                                   &  10000 &  10000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florentdelgrange/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(df.to_latex(float_format=\"${:.2g}$\".format, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
