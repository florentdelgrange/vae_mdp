--batch_size
128
--latent_size
16
--relaxed_state_encoder_temperature
0.67
--relaxed_state_prior_temperature
0.5
--kl_annealing_scale_factor
0.
--kl_annealing_growth_rate
5e-5
--action_discretizer
--number_of_discrete_actions
5
--parallel_env
8
--environment
LunarLanderContinuous-v2
--policy_environment
LunarLanderContinuous-v2
--env_suite
suite_gym
--entropy_regularizer_scale_factor
10
--entropy_regularizer_decay_rate
1e-5
--action_entropy_regularizer_scaling
1e-1
--policy_path=reinforcement_learning/saves/LunarLanderContinuous-v2/sac_policy
--prioritized_experience_replay
--priority_exponent
0.3
--buckets_based_priority=False
--importance_sampling_exponent
0.4
--importance_sampling_exponent_growth_rate
1e-5
--epsilon_greedy
0.
--checkpoint=True
--evaluation_window_size=0
--local_losses_evaluation
--local_losses_evaluation_steps
34000
--local_losses_replay_buffer_size
200000
--max_steps
1000000
