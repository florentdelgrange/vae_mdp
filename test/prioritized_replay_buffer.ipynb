{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import reverb\n",
    "import tf_agents\n",
    "\n",
    "from tf_agents.drivers import dynamic_step_driver, py_driver\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "from tf_agents.environments import suite_gym, parallel_py_environment\n",
    "from tf_agents.environments import tf_py_environment, batched_py_environment\n",
    "from reinforcement_learning import labeling_functions\n",
    "labeling_function = labeling_functions['Pendulum-v0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import policies\n",
    "from util.io.dataset_generator import ErgodicMDPTransitionGenerator\n",
    "\n",
    "env_name = 'Pendulum-v0'\n",
    "py_env = suite_gym.load(env_name)\n",
    "current_time_step = py_env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Environment\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "policy_dir = '../reinforcement_learning/saves/Pendulum-v0/policy'\n",
    "policy = policies.SavedTFPolicy(policy_dir)\n",
    "# transforms policy into a py policy because reverb replay directly interacts with py_env (and not a tf_env)\n",
    "py_policy = py_tf_eager_policy.PyTFEagerPolicy(policy, use_tf_function=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Collect Policy\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "table_name = 'prioritized_replay_buffer'\n",
    "checkpoint_path = '../saves/checkpoint/reverb_test'\n",
    "\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=int(1e6),\n",
    "    sampler=reverb.selectors.Prioritized(priority_exponent=0.6),\n",
    "    remover=reverb.selectors.MaxHeap(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1))\n",
    "\n",
    "checkpointer = reverb.checkpointers.DefaultCheckpointer(checkpoint_path)\n",
    "\n",
    "reverb_server = reverb.Server([table], checkpointer=checkpointer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reverb replay buffer: server\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "TableInfo(name='prioritized_replay_buffer', sampler_options=prioritized {\n  priority_exponent: 0.6\n}\n, remover_options=heap {\n}\nis_deterministic: true\n, max_size=1000000, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0\nmin_diff: -1.7976931348623157e+308\nmax_diff: 1.7976931348623157e+308\nmin_size_to_sample: 1\ninsert_stats {\n  completed_wait_time {\n  }\n  pending_wait_time {\n  }\n}\nsample_stats {\n  completed_wait_time {\n  }\n  pending_wait_time {\n  }\n}\n, signature=None, current_size=15432, num_episodes=2, num_deleted_episodes=0)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverb_replay = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    data_spec=policy.collect_data_spec,\n",
    "    sequence_length=2,\n",
    "    table_name=table_name,\n",
    "    local_server=reverb_server)\n",
    "\n",
    "reverb_replay.get_table_info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reverb replay buffer: client\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "dataset = reverb_replay.as_dataset(\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "dataset_iterator = iter(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reverb replay buffer: dataset\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "observer = reverb_utils.ReverbTrajectorySequenceObserver(\n",
    "    py_client=reverb_replay.py_client,\n",
    "    table_name=table_name,\n",
    "    sequence_length=2,\n",
    "    stride_length=1,\n",
    "    priority=tf.constant(1., dtype=tf.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reverb replay buffer: add item observer\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "num_steps = 5120\n",
    "driver = py_driver.PyDriver(\n",
    "    env=py_env, policy=py_policy, observers=[observer], max_steps=num_steps,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% (py) Driver\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "TableInfo(name='prioritized_replay_buffer', sampler_options=prioritized {\n  priority_exponent: 0.6\n}\n, remover_options=heap {\n}\nis_deterministic: true\n, max_size=1000000, max_times_sampled=0, rate_limiter_info=samples_per_insert: 1.0\nmin_diff: -1.7976931348623157e+308\nmax_diff: 1.7976931348623157e+308\nmin_size_to_sample: 1\ninsert_stats {\n  completed: 5143\n  completed_wait_time {\n  }\n  pending_wait_time {\n  }\n}\nsample_stats {\n  completed_wait_time {\n  }\n  pending_wait_time {\n  }\n}\n, signature=None, current_size=15432, num_episodes=2, num_deleted_episodes=0)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.run(time_step=py_env.current_time_step())\n",
    "reverb_replay.py_client.checkpoint()\n",
    "reverb_replay.get_table_info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% run\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(Trajectory(step_type=<tf.Tensor: shape=(8, 2), dtype=int32, numpy=\n array([[1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1]], dtype=int32)>, observation=<tf.Tensor: shape=(8, 2, 3), dtype=float32, numpy=\n array([[[ 0.7388385 , -0.67388254, -0.82901365],\n         [ 0.69987863, -0.71426183, -1.1223515 ]],\n \n        [[ 0.5747614 , -0.81832105, -1.6312705 ],\n         [ 0.4867845 , -0.8735221 , -2.0781534 ]],\n \n        [[ 0.9725067 ,  0.2328748 ,  0.23582403],\n         [ 0.97024345,  0.24213134,  0.19058491]],\n \n        [[ 0.9913364 , -0.13134722, -0.49659005],\n         [ 0.9882166 , -0.15306222, -0.43876857]],\n \n        [[ 0.9853056 , -0.17080058, -0.35951707],\n         [ 0.98237467, -0.18692261, -0.3277294 ]],\n \n        [[ 0.9934162 , -0.11456145,  0.6380821 ],\n         [ 0.9963247 , -0.08565653,  0.581038  ]],\n \n        [[ 0.6984104 ,  0.71569747, -2.2532053 ],\n         [ 0.7631587 ,  0.64621115, -1.9002608 ]],\n \n        [[ 0.9653485 ,  0.26096424,  0.11561898],\n         [ 0.96464795,  0.26354197,  0.05342439]]], dtype=float32)>, action=<tf.Tensor: shape=(8, 2, 1), dtype=float32, numpy=\n array([[[ 1.4138272 ],\n         [ 1.6187804 ]],\n \n        [[ 1.1123862 ],\n         [ 0.6223793 ]],\n \n        [[-1.4659681 ],\n         [-1.6232861 ]],\n \n        [[ 1.0422127 ],\n         [ 1.2936543 ]],\n \n        [[ 1.0659208 ],\n         [ 0.88930875]],\n \n        [[ 0.19251327],\n         [ 0.4592605 ]],\n \n        [[-1.2255242 ],\n         [-1.0948577 ]],\n \n        [[-1.7194519 ],\n         [-1.8279325 ]]], dtype=float32)>, policy_info=(), next_step_type=<tf.Tensor: shape=(8, 2), dtype=int32, numpy=\n array([[1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1],\n        [1, 1]], dtype=int32)>, reward=<tf.Tensor: shape=(8, 2), dtype=float32, numpy=\n array([[-0.61751336, -0.76151747],\n        [-1.1860329 , -1.5609351 ],\n        [-0.06295073, -0.06607787],\n        [-0.0430986 , -0.04453865],\n        [-0.04352246, -0.04688628],\n        [-0.05393408, -0.04132649],\n        [-1.1453966 , -0.8559575 ],\n        [-0.07400034, -0.07475146]], dtype=float32)>, discount=<tf.Tensor: shape=(8, 2), dtype=float32, numpy=\n array([[1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.]], dtype=float32)>),\n SampleInfo(key=<tf.Tensor: shape=(8, 2), dtype=uint64, numpy=\n array([[17776645022728474486, 17776645022728474486],\n        [18035343202780738709, 18035343202780738709],\n        [ 3773660617496248777,  3773660617496248777],\n        [  999035507386780663,   999035507386780663],\n        [11875515482406473206, 11875515482406473206],\n        [ 8999284635543646428,  8999284635543646428],\n        [12451831519129105823, 12451831519129105823],\n        [ 7446817541480624325,  7446817541480624325]], dtype=uint64)>, probability=<tf.Tensor: shape=(8, 2), dtype=float64, numpy=\n array([[0.00019678, 0.00019678],\n        [0.00019678, 0.00019678],\n        [0.00019678, 0.00019678],\n        [0.00019678, 0.00019678],\n        [0.00019678, 0.00019678],\n        [0.00019678, 0.00019678],\n        [0.00019678, 0.00019678],\n        [0.00019678, 0.00019678]])>, table_size=<tf.Tensor: shape=(8, 2), dtype=int64, numpy=\n array([[5143, 5143],\n        [5143, 5143],\n        [5143, 5143],\n        [5143, 5143],\n        [5143, 5143],\n        [5143, 5143],\n        [5143, 5143],\n        [5143, 5143]])>, priority=<tf.Tensor: shape=(8, 2), dtype=float64, numpy=\n array([[1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 1.]])>))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj = next(dataset_iterator)\n",
    "traj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "reverb_replay.update_priorities(traj[1].key[..., 0], 1./3 * tf.ones(shape=(batch_size,), dtype=tf.float64))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5143\n"
     ]
    },
    {
     "data": {
      "text/plain": "'../saves/checkpoint/reverb_test/2021-04-26T18:20:07.832703724+02:00'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reverb_replay.get_table_info().current_size)\n",
    "reverb_replay.py_client.checkpoint()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_entropy_regularizer_81377) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_entropy_regularizer_81377) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_entropy_regularizer_81377) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_82873) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_82873) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_82873) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_82652) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_82652) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_82652) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88731) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88731) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88731) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_90141) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_90141) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_90141) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88799) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88799) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88799) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE MDP loaded\n"
     ]
    }
   ],
   "source": [
    "import variational_action_discretizer\n",
    "\n",
    "vae_mdp = variational_action_discretizer.load(\n",
    "    '../saves/Pendulum-v0/models/vae_LS12_MC1_ER10.0-decay=7.5e-05-min=0_KLA0.0-growth=5e-05_TD0.67-0.50_1e-06-2e-06_seed=20421/policy/action_discretizer/LA3_MC1_ER10.0-decay=7.5e-05-min=0_KLA0.0-growth=5e-05_TD0.50-0.33_1e-06-2e-06_params=full_vae_optimization-relaxed_state_encoding/base',\n",
    "    step=1830000\n",
    ")\n",
    "print(\"VAE MDP loaded\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Variational MDP\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\n",
    "generator = ErgodicMDPTransitionGenerator(\n",
    "    labeling_function=labeling_function,\n",
    "    replay_buffer=reverb_replay,\n",
    "    discrete_action=False,\n",
    "    prioritized_replay_buffer=True,\n",
    "    state_embedding_function=lambda state, label: tf.squeeze(\n",
    "        vae_mdp.binary_encode(tf.expand_dims(state, axis=0), tf.expand_dims(label, axis=0)).mode()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Ergodic MDP generator\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "dataset = reverb_replay.as_dataset(\n",
    "    num_steps=2,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ").map(map_func=generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "dataset_iterator = iter(dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reverb replay buffer: ergodic MDP dataset\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n array([[ 0.99993664,  0.01125781,  0.5358942 ],\n        [ 0.9816694 ,  0.19059162,  0.31015158],\n        [-0.29377538,  0.9558745 , -5.620201  ],\n        [ 0.97343564,  0.22896075, -0.34662813],\n        [ 0.99237573, -0.12324932, -0.35998908],\n        [ 0.9571976 ,  0.28943527, -0.4271448 ],\n        [ 0.9930223 , -0.11792643,  0.67813486],\n        [-0.18458012, -0.9828175 ,  4.9253883 ]], dtype=float32)>,\n <tf.Tensor: shape=(8, 4), dtype=float32, numpy=\n array([[1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [0., 0., 0., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [0., 0., 0., 0.]], dtype=float32)>,\n <tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n array([[-0.2599124 ],\n        [-1.1269883 ],\n        [-0.5246502 ],\n        [-0.968116  ],\n        [ 0.6597317 ],\n        [-1.0723196 ],\n        [ 0.32941908],\n        [ 0.6956657 ]], dtype=float32)>,\n <tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n array([[-0.02891256],\n        [-0.04766323],\n        [-6.651992  ],\n        [-0.06631795],\n        [-0.0286624 ],\n        [-0.1056177 ],\n        [-0.06006679],\n        [-5.5115137 ]], dtype=float32)>,\n <tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n array([[ 0.999333  ,  0.03651746,  0.5053507 ],\n        [ 0.97886366,  0.20451394,  0.28404707],\n        [-0.04905477,  0.9987961 , -4.9819927 ],\n        [ 0.9769756 ,  0.21335103, -0.32012498],\n        [ 0.9900426 , -0.14076772, -0.3534663 ],\n        [ 0.9624005 ,  0.2716345 , -0.3709163 ],\n        [ 0.9962831 , -0.08613946,  0.6391029 ],\n        [ 0.02898257, -0.9995799 ,  4.292625  ]], dtype=float32)>,\n <tf.Tensor: shape=(8, 4), dtype=float32, numpy=\n array([[1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [0., 0., 0., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 0., 0., 0.]], dtype=float32)>,\n <tf.Tensor: shape=(8,), dtype=float64, numpy=\n array([0.5       , 0.66666667, 0.66666667, 0.75      , 0.8       ,\n        0.83333333, 0.85714286, 0.875     ])>)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataset_iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<TakeDataset shapes: ((3,), (None,), (1,), <unknown>, (3,), (None,), ()), types: (tf.float32, tf.float32, tf.float32, tf.float32, tf.float32, tf.float32, tf.float64)>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int32, numpy=12>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_embedding_function = lambda state, label: tf.squeeze(\n",
    "        vae_mdp.binary_encode(tf.expand_dims(state, axis=0), tf.expand_dims(label, axis=0)).mode())\n",
    "generator.latent_state_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "TimeStep(step_type=array([0, 0, 0, 0, 0], dtype=int32), reward=array([0., 0., 0., 0., 0.], dtype=float32), discount=array([1., 1., 1., 1., 1.], dtype=float32), observation=array([[-0.98478675, -0.17376737, -0.75586486],\n       [ 0.20625967,  0.97849727,  0.84964657],\n       [-0.782991  ,  0.62203306, -0.08362035],\n       [ 0.6861767 ,  0.7274349 ,  0.98699635],\n       [-0.16147746,  0.9868764 , -0.8903516 ]], dtype=float32))"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_agents.system.multiprocessing.enable_interactive_mode()\n",
    "py_env = parallel_py_environment.ParallelPyEnvironment(\n",
    "    [lambda: suite_gym.load(env_name)] * 5)\n",
    "py_env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "observer.close()\n",
    "reverb_server.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}