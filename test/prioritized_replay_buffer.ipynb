{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import reverb\n",
    "\n",
    "from tf_agents.drivers import dynamic_step_driver, py_driver\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment, batched_py_environment\n",
    "from reinforcement_learning import labeling_functions\n",
    "labeling_function = labeling_functions['Pendulum-v0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import policies\n",
    "from util.io.dataset_generator import ErgodicMDPTransitionGenerator\n",
    "\n",
    "env_name = 'Pendulum-v0'\n",
    "py_env = suite_gym.load(env_name)\n",
    "current_time_step = py_env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Environment\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "policy_dir = '../reinforcement_learning/saves/Pendulum-v0/policy'\n",
    "policy = policies.SavedTFPolicy(policy_dir)\n",
    "# transforms policy into a py policy because reverb replay directly interacts with py_env (and not a tf_env)\n",
    "py_policy = py_tf_eager_policy.PyTFEagerPolicy(policy, use_tf_function=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Collect Policy\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "table_name = 'prioritized_replay_buffer'\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=int(1e6),\n",
    "    sampler=reverb.selectors.Prioritized(priority_exponent=0.6),\n",
    "    remover=reverb.selectors.MaxHeap(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1))\n",
    "\n",
    "reverb_server = reverb.Server([table])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reverb replay buffer: server\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "reverb_replay = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    data_spec=policy.collect_data_spec,\n",
    "    sequence_length=2,\n",
    "    table_name=table_name,\n",
    "    local_server=reverb_server)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reverb replay buffer: client\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "dataset = reverb_replay.as_dataset(\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "dataset_iterator = iter(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reverb replay buffer: dataset\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "observer = reverb_utils.ReverbTrajectorySequenceObserver(\n",
    "    py_client=reverb_replay.py_client,\n",
    "    table_name=table_name,\n",
    "    sequence_length=2,\n",
    "    stride_length=1,\n",
    "    priority=tf.constant(1., dtype=tf.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reverb replay buffer: add item observer\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "num_steps = 5120\n",
    "driver = py_driver.PyDriver(\n",
    "    env=py_env, policy=py_policy, observers=[observer], max_steps=num_steps,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% (py) Driver\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "current_time_step = driver.run(time_step=current_time_step)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% run\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "traj = next(dataset_iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "reverb_replay.update_priorities(traj[1].key[..., 0], 1./3 * tf.ones(shape=(batch_size,), dtype=tf.float64))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "5143"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverb_replay.get_table_info().current_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_entropy_regularizer_81377) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_entropy_regularizer_81377) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_entropy_regularizer_81377) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_82873) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_82873) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_82873) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_82652) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_82652) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_82652) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88731) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88731) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88731) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_90141) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_90141) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_latent_distribution_logits_layer_call_and_return_conditional_losses_90141) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88799) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88799) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_encoder_layer_call_and_return_conditional_losses_88799) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___88524) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference___call___82367) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE MDP loaded\n"
     ]
    }
   ],
   "source": [
    "import variational_action_discretizer\n",
    "\n",
    "vae_mdp = variational_action_discretizer.load(\n",
    "    '../saves/Pendulum-v0/models/vae_LS12_MC1_ER10.0-decay=7.5e-05-min=0_KLA0.0-growth=5e-05_TD0.67-0.50_1e-06-2e-06_seed=20421/policy/action_discretizer/LA3_MC1_ER10.0-decay=7.5e-05-min=0_KLA0.0-growth=5e-05_TD0.50-0.33_1e-06-2e-06_params=full_vae_optimization-relaxed_state_encoding/base',\n",
    "    step=1830000\n",
    ")\n",
    "print(\"VAE MDP loaded\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Variational MDP\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\n",
    "generator = ErgodicMDPTransitionGenerator(\n",
    "    labeling_function=labeling_function,\n",
    "    replay_buffer=reverb_replay,\n",
    "    discrete_action=False,\n",
    "    prioritized_replay_buffer=True,\n",
    "    state_embedding_function=lambda state, label: tf.squeeze(\n",
    "        vae_mdp.binary_encode(tf.expand_dims(state, axis=0), tf.expand_dims(label, axis=0)).mode()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Ergodic MDP generator\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "dataset = reverb_replay.as_dataset(\n",
    "    num_steps=2,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ").map(map_func=generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "dataset_iterator = iter(dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Reverb replay buffer: ergodic MDP dataset\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n array([[ 0.99993664,  0.01125781,  0.5358942 ],\n        [ 0.9816694 ,  0.19059162,  0.31015158],\n        [-0.29377538,  0.9558745 , -5.620201  ],\n        [ 0.97343564,  0.22896075, -0.34662813],\n        [ 0.99237573, -0.12324932, -0.35998908],\n        [ 0.9571976 ,  0.28943527, -0.4271448 ],\n        [ 0.9930223 , -0.11792643,  0.67813486],\n        [-0.18458012, -0.9828175 ,  4.9253883 ]], dtype=float32)>,\n <tf.Tensor: shape=(8, 4), dtype=float32, numpy=\n array([[1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [0., 0., 0., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [0., 0., 0., 0.]], dtype=float32)>,\n <tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n array([[-0.2599124 ],\n        [-1.1269883 ],\n        [-0.5246502 ],\n        [-0.968116  ],\n        [ 0.6597317 ],\n        [-1.0723196 ],\n        [ 0.32941908],\n        [ 0.6956657 ]], dtype=float32)>,\n <tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n array([[-0.02891256],\n        [-0.04766323],\n        [-6.651992  ],\n        [-0.06631795],\n        [-0.0286624 ],\n        [-0.1056177 ],\n        [-0.06006679],\n        [-5.5115137 ]], dtype=float32)>,\n <tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n array([[ 0.999333  ,  0.03651746,  0.5053507 ],\n        [ 0.97886366,  0.20451394,  0.28404707],\n        [-0.04905477,  0.9987961 , -4.9819927 ],\n        [ 0.9769756 ,  0.21335103, -0.32012498],\n        [ 0.9900426 , -0.14076772, -0.3534663 ],\n        [ 0.9624005 ,  0.2716345 , -0.3709163 ],\n        [ 0.9962831 , -0.08613946,  0.6391029 ],\n        [ 0.02898257, -0.9995799 ,  4.292625  ]], dtype=float32)>,\n <tf.Tensor: shape=(8, 4), dtype=float32, numpy=\n array([[1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [0., 0., 0., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 0., 0., 0.]], dtype=float32)>,\n <tf.Tensor: shape=(8,), dtype=float64, numpy=\n array([0.5       , 0.66666667, 0.66666667, 0.75      , 0.8       ,\n        0.83333333, 0.85714286, 0.875     ])>)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataset_iterator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<TakeDataset shapes: ((3,), (None,), (1,), <unknown>, (3,), (None,), ()), types: (tf.float32, tf.float32, tf.float32, tf.float32, tf.float32, tf.float32, tf.float64)>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int32, numpy=12>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_embedding_function = lambda state, label: tf.squeeze(\n",
    "        vae_mdp.binary_encode(tf.expand_dims(state, axis=0), tf.expand_dims(label, axis=0)).mode())\n",
    "generator.latent_state_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}